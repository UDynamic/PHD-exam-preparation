#separator:tab
#html:true
#guid column:1
#notetype column:2
#deck column:3
#tags column:6

gw.ao-4QO+	Basic	ML-holdOut&crossValidation	What is simple holdout and its main limitation?	A single split (typically 70-80% train, 20-30% test).<br><br>Limitation: High variance in performance estimates due to sensitivity to that one random split.
G=W$!i>KdB	Basic	ML-holdOut&crossValidation	Why use a three-way split instead of two-way?	Three splits allow separate phases: Training (fit model), Validation (tune hyperparameters), and Testing (final unbiased evaluation). Prevents data leakage from tuning into final metrics.
PmUbP:@@{N	Basic	ML-holdOut&crossValidation	What defines random holdout and when is it appropriate?	Data points are randomly assigned to splits. Appropriate when data is IID (Independent and Identically Distributed) and balanced.
N8eL!a7@+R	Basic	ML-holdOut&crossValidation	What is stratified holdout and when is it crucial?	Splits preserve the original class/group proportions in each subset. Crucial for classification with imbalanced datasets to ensure all splits represent all classes.
Z5qKd^Vc2T	Basic	ML-holdOut&crossValidation	How can you diagnose underfitting vs. overfitting using holdout?	High train AND test error → Underfitting (High Bias). Low train error but high test error → Overfitting (High Variance).
B3mG#e9L*Y	Basic	ML-holdOut&crossValidation	What is the main statistical trade-off of using holdout?	Reduces BIAS in performance estimation (gives honest, pessimistic estimate) but increases VARIANCE (single split gives unstable estimate). For lower variance, use cross-validation.
F7jH&kS1!Q	Basic	ML-holdOut&crossValidation	When is holdout preferable over cross-validation?	With very large datasets (\(>10k\) samples), for quick prototyping, or with limited computational resources.
X2tR@pL9$U	Basic	ML-holdOut&crossValidation	What is the fundamental limitation of any holdout method?	It wastes data. Part of the dataset is withheld from training the model, which can be problematic with small datasets.
C4vM%nD3#W	Basic	ML-holdOut&crossValidation	What is the fundamental idea behind cross-validation?	Repeatedly partitioning data into training and validation sets to use all data points for both training and validation, providing a more robust performance estimate than a single holdout split.
V6bN$fE5@R	Basic	ML-holdOut&crossValidation	What problem does cross-validation solve that holdout doesn't?	CV reduces the **high variance** (unstable estimates) of single holdout splits by averaging performance across multiple splits, while maintaining **low bias** (unbiased estimates).
K9aP!jT2*S	Basic	ML-holdOut&crossValidation	Describe the process of standard k-fold CV.	1. Randomly shuffle dataset<br>2. Split into k equal-sized folds<br>3. For i=1 to k:<br>&nbsp;&nbsp;- Use fold i as validation set<br>&nbsp;&nbsp;- Use remaining k-1 folds as training set<br>&nbsp;&nbsp;- Train model, evaluate on fold i<br>4. Average all k performance scores
L1dQ#hG8&F	Basic	ML-holdOut&crossValidation	What are typical k values and the main trade-off?	Common: k=5 or k=10. Trade-off: Higher k → less bias (more training data each iteration) but higher computational cost and potentially higher variance in each estimate.
J3sM!rP7@Z	Basic	ML-holdOut&crossValidation	What is LOOCV and when is it used?	Extreme case where k = n (number of samples). Each iteration uses one sample as validation and n-1 as training. Used for very small datasets to maximize training data.
H2tK$bE4!X	Basic	ML-holdOut&crossValidation	What are the main advantages and disadvantages of LOOCV?	<strong>Advantage:</strong> Virtually unbiased estimate (uses n-1 samples for training each time)<br><br><strong>Disadvantages:</strong> Extremely computationally expensive (n models), high variance in estimates (each test set is just one point)
D5qF@cN9*V	Basic	ML-holdOut&crossValidation	What is stratified k-fold CV and why is it important?	Modified k-fold that preserves class proportions in each fold. Crucial for classification with imbalanced datasets to ensure each fold represents all classes proportionally.
S8aR!tL2#Y	Basic	ML-holdOut&crossValidation	When must you use stratified k-fold over standard?	Always use stratified for classification problems, especially with imbalanced classes. For regression or balanced classification, standard k-fold may suffice.
G1mW%jP5!B	Basic	ML-holdOut&crossValidation	When should you choose CV over holdout?	Choose CV when: dataset is small/medium (\(<10k\) samples), computational cost is acceptable, and you need stable, reliable performance estimates.
E4fS#nD8*H	Basic	ML-holdOut&crossValidation	What does the average CV score actually estimate?	It estimates model performance when trained on all available data (since each training set is almost the full dataset), giving better guidance for final model deployment.
M9rK$bT3@C	Basic	ML-holdOut&crossValidation	Rank CV methods by computational cost (lowest to highest).	Standard K-Fold < Stratified K-Fold \(<<\) Leave-One-Out (with LOOCV being n times more expensive than training one model).
T2pL!qH6#N	Basic	ML-holdOut&crossValidation	What is Leave-P-Out Cross-Validation (LPOCV)?	A generalized cross-validation method where P data points are held out for validation each iteration, and the model is trained on the remaining n-P points, repeated for ALL possible combinations of P points.
Q7vM@jR4!W	Basic	ML-holdOut&crossValidation	How does LPOCV relate to LOOCV and k-fold CV?	LOOCV is a special case of LPOCV where P=1. K-fold CV is a practical approximation/sampling of LPOCV space that's computationally feasible.
P3nS!kF9*Z	Basic	ML-holdOut&crossValidation	How many iterations does LPOCV require for a dataset of size n?	\(C(n, P) = n! / (P! × (n-P)!)\) iterations, which grows combinatorially.
R8bH%tG2!X	Basic	ML-holdOut&crossValidation	What happens when P=1 and P=n/2 in LPOCV?	P=1 → LOOCV (n iterations). P=n/2 → all possible half/half splits (maximum combinations).
A1cW!fE7@V	Basic	ML-holdOut&crossValidation	When might LPOCV actually be feasible?	Only with very small datasets (n<20) and small P values (P≤3), or when computation cost is irrelevant.
U6dF#mB5!Y	Basic	ML-holdOut&crossValidation	What is Monte Carlo Cross-Validation?	Repeated random splitting of data into train/test sets over many iterations, with no requirement for exhaustive or non-overlapping test sets.
I9sL$pR2!N	Basic	ML-holdOut&crossValidation	What other names is Monte Carlo CV known by?	Repeated Random Subsampling or Shuffle-Split Cross-Validation.
O4tK!jH8@B	Basic	ML-holdOut&crossValidation	How does Monte Carlo CV differ fundamentally from k-fold CV?	In Monte Carlo, test sets can overlap across iterations and some data points might never be tested, unlike k-fold where each point is tested exactly once.
Y5rM#nT3!C	Basic	ML-holdOut&crossValidation	What three parameters do you specify for Monte Carlo CV?	Number of iterations, training set percentage/size, and test set percentage/size.
W2qS$bF6!H	Basic	ML-holdOut&crossValidation	What's the main disadvantage of Monte Carlo compared to k-fold?	Not exhaustive - some data points might never be included in test sets by random chance.
J7vP!kG9!Z	Basic	ML-holdOut&crossValidation	When is Monte Carlo CV particularly useful?	With very large datasets where exhaustive testing is unnecessary, or when exploring how performance varies with different random splits.
L3nH$tE2!X	Basic	ML-holdOut&crossValidation	How is Monte Carlo CV related to simple holdout?	It's essentially repeated random holdout splits, averaging many single holdout estimates to reduce variance.