{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd0c9cb0",
   "metadata": {},
   "source": [
    "\n",
    "## Linear Combination Definition\n",
    "**Front:** What is $\\theta^T X$ in the context of logistic regression? <br/>\n",
    "**Back:** It is the **linear combination** (or dot product) between the parameter vector $\\theta$ and the input feature vector $X$. Mathematically: $\\theta^T X = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... + \\theta_n x_n$, where $\\theta_0$ is the bias/intercept term (often with $x_0 = 1$ included in $X$).\n",
    "\n",
    "\n",
    "## Geometric Interpretation\n",
    "**Front:** Geometrically, what does $\\theta^T X = 0$ represent? <br/>\n",
    "**Back:** It defines a **hyperplane** (e.g., a line in 2D) in the feature space. This hyperplane is the **decision boundary** where the model predicts exactly 0.5 probability for both classes.\n",
    "\n",
    "\n",
    "## Hypothesis Function\n",
    "**Front:** In binary logistic regression, what function replaces the linear hypothesis $h_\\theta(x) = \\theta^T x$? <br/>\n",
    "**Back:** for activation function as $g(x)$ : $h_\\theta(x) = g(\\theta^T x)$\n",
    "\n",
    "* The sigmoid activation function: $h_\\theta(x) = \\sigma(\\theta^T x) = \\frac{1}{1 + e^{-\\theta^T x}}$.\n",
    "\n",
    "$ 0 \\leq h_\\theta(x) \\leq 1 $\n",
    "\n",
    "## Role in Hypothesis Function\n",
    "**Front:** What is the role of $\\theta^T X$ in the logistic regression hypothesis function $h_\\theta(x)$? <br/>\n",
    "**Back:** $\\theta^T X$ serves as the input to the sigmoid function: $h_\\theta(x) = \\sigma(\\theta^T X) = \\frac{1}{1 + e^{-\\theta^T X}}$. It is the **linear predictor** or **logit**.\n",
    "\n",
    "## Probabilistic Interpretation (Class 1)\n",
    "**Front:** How is the hypothesis $h_\\theta(x)$ interpreted probabilistically for binary classification? <br/>\n",
    "**Back:** $h_\\theta(x)$ represents the estimated probability that $y=1$ given $x$: \n",
    "\n",
    "$p(y=1|x;\\theta) = h_\\theta(x)$.\n",
    "\n",
    "## Probabilistic Interpretation (Class 0)\n",
    "**Front:** What is the probability that $y=0$ given $x$ in binary logistic regression? <br/>\n",
    "**Back:** \n",
    "\n",
    "$p(y=0|x;\\theta) = 1 - p(y=1|x;\\theta) = 1 - h_\\theta(x)$.\n",
    "\n",
    "## Compact Probability Expression\n",
    "**Front:** How can we write the probability $p(y|x;\\theta)$ for both classes ($y=0$ or $y=1$) in a single formula? <br/>\n",
    "**Back:** \n",
    "\n",
    "$p(y|x;\\theta) = (h_\\theta(x))^{y} \\cdot (1 - h_\\theta(x))^{1-y}$. \n",
    "\n",
    "## Decision Boundary Definition\n",
    "**Front:** What is the decision boundary in logistic regression, and where is it located? <br/>\n",
    "**Back:** It is the set of points $x$ where $p(y=1|x;\\theta) = p(y=0|x;\\theta) = 0.5$. \n",
    "\n",
    "This occurs when $\\theta^T x = 0$.\n",
    "\n",
    "## Region of Positive Prediction\n",
    "**Front:** For what values of θᵀx will the model predict y=1? <br/>\n",
    "**Back:** When θᵀx > 0, which means h_θ(x) = σ(θᵀx) > 0.5. The model predicts class 1 in this region.\n",
    "\n",
    "## Region of Negative Prediction\n",
    "**Front:** For what values of θᵀx will the model predict y=0? <br/>\n",
    "**Back:** When θᵀx < 0, which means h_θ(x) = σ(θᵀx) < 0.5. The model predicts class 0 in this region.\n",
    "\n",
    "## Likelihood Function\n",
    "**Front:** For a training set of $m$ i.i.d. examples, what is the likelihood function $L(\\theta)$? <br/>\n",
    "**Back:** The product of individual probabilities: $L(\\theta) = \\prod_{i=1}^m p(y^{(i)}|x^{(i)};\\theta) = \\prod_{i=1}^m (h_\\theta(x^{(i)}))^{y^{(i)}} (1-h_\\theta(x^{(i)}))^{1-y^{(i)}}$.\n",
    "\n",
    "* this is a Mximization problem\n",
    "\n",
    "## Log-Likelihood\n",
    "**Front:** Why do we take the log of the likelihood, and what is $l(\\theta) = \\log L(\\theta)$? <br/>\n",
    "**Back:** Log transforms products into sums, simplifying calculus. $l(\\theta) = \\sum_{i=1}^m [y^{(i)} \\log h_\\theta(x^{(i)}) + (1-y^{(i)}) \\log(1-h_\\theta(x^{(i)}))]$.\n",
    "\n",
    "* this is a Mximization problem\n",
    "\n",
    "## Cost Function (Negative Log-Likelihood)\n",
    "**Front:** What is the standard cost function $J(\\theta)$ for logistic regression, and how is it derived? <br/>\n",
    "**Back:** It is the average negative log-likelihood. <br/>\n",
    "$J(\\theta) = -l(\\theta) = - \\sum_{i=1}^m [y^{(i)} \\log h_\\theta(x^{(i)}) + (1-y^{(i)}) \\log(1-h_\\theta(x^{(i)}))]$\n",
    "\n",
    "Average form :<br/>\n",
    "$J(\\theta) = -\\frac{1}{m} l(\\theta)$\n",
    "\n",
    "* Minimizing $J(\\theta)$ is equivalent to maximizing the likelihood $L(\\theta)$.\n",
    "\n",
    "## Sum of Squared Errors (SSE) Problem\n",
    "**Front:** In linear regression, the cost function is Sum of Squared Errors (SSE). Why would SSE be a poor choice for logistic regression? <br/>\n",
    "**Back:** SSE $J(\\theta) = \\frac{1}{2}\\sum (h_\\theta(x^{(i)}) - y^{(i)})^2$ applied to $h_\\theta(x)=\\sigma(\\theta^T x)$ yields a **non-convex** function with many local minima. Gradient descent might not find the global optimum.\n",
    "\n",
    "## Gradient Descent Update Rule\n",
    "**Front:** What is the parameter update rule for gradient descent using the cost $J(\\theta) = - l(\\theta)$? <br/>\n",
    "**Back:** \n",
    "General form: $ \\begin{cases} \\theta_j := \\theta_j - \\alpha \\frac{\\partial J(\\theta)}{\\partial \\theta_j}\\\\ \\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)}) x_j^{(i)} \\end{cases}$\n",
    "\n",
    "$\\Rightarrow$\n",
    "$ \\begin{cases} \\Delta \\theta_0 = - \\alpha[\\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})] & j=0\\\\ \\Delta \\theta_j = - \\alpha[\\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)}) x_j^{(i)}] & j \\geq 1\\end{cases}$\n",
    "\n",
    "## Special Consideration: Regularization in Cost\n",
    "**Front:** How is L2 regularization typically added to the logistic regression cost function $J(\\theta)$? <br/>\n",
    "**Back:** $J_{reg}(\\theta) = -l(\\theta) + \\frac{\\lambda}{2} \\sum_{j=1}^n \\theta_j^2$. \n",
    "\n",
    "The bias term $\\theta_0$ is often excluded from regularization.\n",
    "\n",
    "## Gradient Descent Update Rule with L2 regularization\n",
    "**Front:** What is the parameter update rule for gradient descent using L2 regularization? <br/>\n",
    "**Back:** \n",
    "General form: \n",
    "$ \\begin{cases} J(\\theta) = - l(\\theta) + \\frac{\\lambda}{2} \\sum_{j=1}^n \\theta^2 \n",
    "\\\\ \\theta_j := \\theta_j - \\alpha \\frac{\\partial J(\\theta)}{\\partial \\theta_j} \n",
    "\\\\ \\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)}) x_j^{(i)} + \\lambda \\theta_j\\end{cases}$\n",
    "\n",
    "$\\Rightarrow$\n",
    "$ \\begin{cases} \\Delta \\theta_0 = - \\alpha[\\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})] & j=0\\\\ \\Delta \\theta_j = - \\alpha[\\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)}) x_j^{(i)} + \\lambda \\theta_j] & j \\geq 1\\end{cases}$\n",
    "\n",
    "## Derivative of the Sigmoid\n",
    "**Front:** What is the derivative of the sigmoid function $\\sigma(z)$, and why is this useful? <br/>\n",
    "**Back:** $\\frac{d}{dz}\\sigma(z) = \\sigma(z)(1 - \\sigma(z))$. This simplifies the gradient calculation for the log-likelihood.\n",
    "\n",
    "## Multi-class: One-vs-Rest (OvR)\n",
    "**Front:** How does the One-vs-Rest (OvR) strategy work for multi-class classification with logistic regression? <br/>\n",
    "**Back:** For $K$ classes, train $K$ separate binary classifiers. Classifier $k$ learns to distinguish class $k$ (positive) from all other classes (negative). Prediction is the class with the highest $h_\\theta^{(k)}(x)$.\n",
    "\n",
    "## Multi-class: One-vs-One (OvO)\n",
    "**Front:** How does the One-vs-One (OvO) strategy work? <br/>\n",
    "**Back:** Train a binary classifier for every pair of classes. This requires $\\binom{K}{2} = \\frac{K(K-1)}{2}$ classifiers. Prediction is made by majority vote from all classifiers.\n",
    "\n",
    "## Multi-class: Softmax Regression\n",
    "**Front:** What is the direct multi-class generalization of logistic regression called, and what is its hypothesis function? <br/>\n",
    "**Back:** Softmax Regression. For class $k$ with parameters $\\theta^{(k)}$, $p(y=k|x;\\Theta) = \\frac{e^{\\theta^{(k)T} x}}{\\sum_{j=1}^K e^{\\theta^{(j)T} x}}$, where $\\Theta$ is the matrix of all parameters.\n",
    "\n",
    "## Softmax Decision Boundaries\n",
    "**Front:** In softmax regression, what is the nature of the decision boundary between any two classes $k$ and $l$? <br/>\n",
    "**Back:** The boundary where $p(y=k|x) = p(y=l|x)$ is linear, defined by $(\\theta^{(k)} - \\theta^{(l)})^T x = 0$.\n",
    "\n",
    "## Softmax Cost Function\n",
    "**Front:** What is the cost function for softmax regression, and what is it called? <br/>\n",
    "**Back:** The categorical cross-entropy: $J(\\Theta) = -\\frac{1}{m} \\sum_{i=1}^m \\sum_{k=1}^K 1\\{y^{(i)}=k\\} \\log \\frac{e^{\\theta^{(k)T} x^{(i)}}}{\\sum_{j=1}^K e^{\\theta^{(j)T} x^{(i)}}}$.\n",
    "\n",
    "## Pitfall: Interpreting Raw Scores\n",
    "**Front:** Before applying the sigmoid or softmax, what do the raw scores $\\theta^T x$ or $\\theta^{(k)T} x$ represent? <br/>\n",
    "**Back:** They are log-odds (for binary) or logits. They exist on the whole real line and are not probabilities. The activation function converts them to probabilities.\n",
    "\n",
    "## Pitfall: Numerical Stability (Softmax)\n",
    "**Front:** What numerical issue can occur when computing $e^{\\theta^{(k)T} x}$ for softmax, and how is it fixed? <br/>\n",
    "**Back:** Large exponents can cause overflow. The fix is to subtract the maximum logit: $p(y=k|x) = \\frac{e^{\\theta^{(k)T} x - C}}{\\sum_j e^{\\theta^{(j)T} x - C}}$, where $C = \\max_j(\\theta^{(j)T} x)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b2666c",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Definition and Purpose\n",
    "**Front:** What is the primary goal of logistic regression? <br/>\n",
    "**Back:** To model the probability that a given input vector $\\mathbf{x}$ belongs to a particular class (e.g., Class 1). It's used for binary classification.\n",
    "\n",
    "## Model Output\n",
    "**Front:** What is the direct output of the logistic regression model for an input $\\mathbf{x}$? <br/>\n",
    "**Back:** A probability value between 0 and 1: $p(C_1|\\mathbf{x})$. The probability for the other class is $p(C_2|\\mathbf{x}) = 1 - p(C_1|\\mathbf{x})$.\n",
    "\n",
    "## Linear Predictor\n",
    "**Front:** What is the \"linear predictor\" or \"activation\" $a$ in logistic regression? <br/>\n",
    "**Back:** A linear combination of the inputs (and a bias): $a = \\mathbf{w}^T \\mathbf{x} + w_0$, where $\\mathbf{w}$ are the weights and $w_0$ is the bias term.\n",
    "\n",
    "## Logistic Sigmoid Function\n",
    "**Front:** What function maps the linear predictor $a$ to a valid probability, and what is its formula? <br/>\n",
    "**Back:** The logistic sigmoid function: $\\sigma(a) = \\frac{1}{1 + \\exp(-a)}$.\n",
    "\n",
    "## Sigmoid Properties\n",
    "**Front:** What are two key mathematical properties of the logistic sigmoid function? <br/>\n",
    "**Back:** 1. It is bounded: $\\sigma(a) \\in (0, 1)$. 2. Its derivative is simple: $\\frac{d\\sigma}{da} = \\sigma(a)(1 - \\sigma(a))$.\n",
    "\n",
    "## Discriminative Model\n",
    "**Front:** What type of model is logistic regression: generative or discriminative? What does it model directly? <br/>\n",
    "**Back:** It is a discriminative model. It directly models the posterior class probability $p(C_k|\\mathbf{x})$, not the class-conditional densities $p(\\mathbf{x}|C_k)$.\n",
    "\n",
    "## Bernoulli Likelihood\n",
    "**Front:** For a single data point with target $t \\in \\{0,1\\}$, what is the probability (likelihood) under the model? <br/>\n",
    "**Back:** $p(t | \\mathbf{x}, \\mathbf{w}) = y^t (1-y)^{1-t}$, where $y = \\sigma(\\mathbf{w}^T\\mathbf{x})$ is the model's predicted probability for class 1.\n",
    "\n",
    "## Cross-Entropy Error Derivation\n",
    "**Front:** How is the error function $E(\\mathbf{w})$ derived from the model likelihood for a full dataset? <br/>\n",
    "**Back:** By taking the negative logarithm of the likelihood function. For N independent points, $E(\\mathbf{w}) = -\\sum_{n=1}^N [t_n \\ln y_n + (1-t_n)\\ln(1-y_n)]$.\n",
    "\n",
    "## Error Function Name\n",
    "**Front:** What is the common name for the error function $E(\\mathbf{w})$ used in logistic regression? <br/>\n",
    "**Back:** The binary cross-entropy error function.\n",
    "\n",
    "## Gradient of the Error\n",
    "**Front:** What is the gradient of the cross-entropy error $E(\\mathbf{w})$ with respect to the weights $\\mathbf{w}$? <br/>\n",
    "**Back:** $\\nabla E(\\mathbf{w}) = \\sum_{n=1}^N (y_n - t_n) \\mathbf{x}_n$. It has a simple form resembling the error times the input.\n",
    "\n",
    "## No Closed-Form Solution\n",
    "**Front:** Can we find a closed-form solution for the optimal weights $\\mathbf{w}$ by setting $\\nabla E(\\mathbf{w}) = 0$? Why or why not? <br/>\n",
    "**Back:** No. Because $y_n = \\sigma(\\mathbf{w}^T\\mathbf{x}_n)$ is a nonlinear function of $\\mathbf{w}$, the gradient equation is nonlinear and has no closed-form solution.\n",
    "\n",
    "## Optimization Method\n",
    "**Front:** What general class of algorithms is required to find the optimal weights in logistic regression? <br/>\n",
    "**Back:** Iterative numerical optimization algorithms, such as gradient descent or Newton's method.\n",
    "\n",
    "## Newton's Method / IRLS\n",
    "**Front:** What is a second-order optimization method used for logistic regression, and what is its common name in this context? <br/>\n",
    "**Back:** Newton-Raphson method. When applied to logistic regression, it's called Iterative Re-weighted Least Squares (IRLS).\n",
    "\n",
    "## IRLS Intuition\n",
    "**Front:** Briefly, why is the Newton-Raphson update for logistic regression called \"Iterative Re-weighted Least Squares\"? <br/>\n",
    "**Back:** Each update step solves a weighted least squares problem, where the weights on the data points depend on the current probability estimates, and these weights are re-computed each iteration.\n",
    "\n",
    "## Multiclass Extension\n",
    "**Front:** What is the standard extension of logistic regression to $K > 2$ classes called? <br/>\n",
    "**Back:** Multinomial logistic regression, or softmax regression.\n",
    "\n",
    "## Softmax Function\n",
    "**Front:** What is the softmax function that generalizes the sigmoid for $K$ classes? <br/>\n",
    "**Back:** For a vector of linear activations $\\mathbf{a}$, the softmax for class $k$ is: $\\text{softmax}(a_k) = \\frac{\\exp(a_k)}{\\sum_{j=1}^K \\exp(a_j)}$.\n",
    "\n",
    "## Linear Decision Boundary\n",
    "**Front:** What is the shape of the decision boundary (where $p(C_1|\\mathbf{x}) = p(C_2|\\mathbf{x})$) in basic logistic regression? <br/>\n",
    "**Back:** It is linear, defined by the equation $\\mathbf{w}^T\\mathbf{x} + w_0 = 0$.\n",
    "\n",
    "## Feature Transforms\n",
    "**Front:** How can logistic regression model nonlinear decision boundaries? <br/>\n",
    "**Back:** By using fixed, nonlinear basis functions $\\phi(\\mathbf{x})$ to transform the input. The model becomes $p(C_1|\\mathbf{x}) = \\sigma(\\mathbf{w}^T\\phi(\\mathbf{x}))$.\n",
    "\n",
    "## Pitfall: Separable Data\n",
    "**Front:** What pathological problem occurs if the training data is perfectly linearly separable? <br/>\n",
    "**Back:** Maximum likelihood estimation will drive the magnitude of $\\mathbf{w}$ to infinity. The sigmoid becomes infinitely steep, outputting overconfident probabilities of 0 or 1.\n",
    "\n",
    "## Pitfall: Overconfidence Consequence\n",
    "**Front:** Why is the \"infinite weights\" solution for separable data undesirable? <br/>\n",
    "**Back:** It represents severe overfitting. The model loses its probabilistic interpretation (becomes a step function) and will generalize poorly, especially near the decision boundary.\n",
    "\n",
    "## Special Consideration: Regularization\n",
    "**Front:** What is the standard technique to prevent the infinite weight problem and control model complexity? <br/>\n",
    "**Back:** Add a regularization term to the error function, e.g., $E_{reg}(\\mathbf{w}) = E(\\mathbf{w}) + \\frac{\\lambda}{2}\\|\\mathbf{w}\\|^2$. This is equivalent to placing a Gaussian prior on the weights (MAP estimation).\n",
    "\n",
    "## Regularization Effect\n",
    "**Front:** How does regularization (e.g., $\\lambda \\|\\mathbf{w}\\|^2$) affect the learned weights and probabilities? <br/>\n",
    "**Back:** It shrinks the weights toward zero, preventing extreme values. This makes the predicted probability curves smoother and less overconfident."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
