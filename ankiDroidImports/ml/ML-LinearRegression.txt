#separator:tab
#html:true
#guid column:1
#notetype column:2
#deck column:3
#tags column:6

dw.ao-4QO+	Basic	ML-LinearRegression	What is the hypothesis function for simple linear regression? <br/>	 \(h_{\theta}(x) = \theta_0 + \theta_1x\), where \(\theta_0\) is the intercept and \(\theta_1\) is the slope. This gives the prediction \(\hat{y}\).
G=W$!i>KdB	Basic	ML-LinearRegression	What is the goal when training a linear regression model? <br/>	To find parameters \(\theta_0, \theta_1\) that minimize the cost function \(J(\theta_0, \theta_1)\).
PmUbP:@@{N	Basic	ML-LinearRegression	What is the Sum of Squared Errors (SSE) cost function? <br/>	 \(J(\theta) = \frac{1}{2} \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})^2\). The \(\frac{1}{2}\) simplifies derivatives.
nPdk2%+9Lp	Basic	ML-LinearRegression	What is Mean Squared Error (MSE) and how does it differ from SSE? <br/>	 \(J(\theta) = \frac{1}{2m} \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})^2\). It averages error by dividing by \(m\), making it comparable across datasets.
kQwE@lMn3*	Basic	ML-LinearRegression	What is Root Mean Squared Error (RMSE)? <br/>	 \(J(\theta) = \sqrt{\frac{1}{2m} \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})^2}\). It's in the same units as \(y\) for easier interpretation.
aLp#7DfGh8	Basic	ML-LinearRegression	What is Mean Absolute Error (MAE) and its key difference from MSE? <br/>	 \(J(\theta) = \frac{1}{m} \sum_{i=1}^m |h_\theta(x^{(i)}) - y^{(i)}|\). Unlike MSE, it's less sensitive to outliers but uses sign() in gradient.
jKl9^0sDf!	Basic	ML-LinearRegression	What are the 3 main steps of Gradient Descent? <br/>	 1. Initialize \(\theta\) randomly. 2. Update: \(\theta_j := \theta_j - \alpha\frac{\partial}{\partial\theta_j}J(\theta)\). 3. Repeat until convergence.
sD5#gH8jKl	Basic	ML-LinearRegression	What are the effects of too small or too large learning rate \(\alpha\)? <br/>	 Too small: very slow convergence. Too large: may overshoot minimum, causing divergence or oscillation.
qWe2#rT4yU	Basic	ML-LinearRegression	How do we know when Gradient Descent has converged? <br/>	 When parameter changes are small: \(|\Delta\theta_j| \leq \epsilon\) for all \(j\), where \(\epsilon\) is a small tolerance.
zXc6*vBn9M	Basic	ML-LinearRegression	Why must Gradient Descent update all parameters simultaneously? <br/>	 To ensure each gradient \(\frac{\partial J}{\partial\theta_j}\) is computed using the same parameter values before any updates.
pLo8*iUj7H	Basic	ML-LinearRegression	What is \(\frac{\partial J}{\partial\theta_0}\) for MSE cost? <br/>	 \(\frac{\partial J}{\partial\theta_0} = \frac{1}{m} \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})\).
mKi9(oP0lZ	Basic	ML-LinearRegression	What is \(\frac{\partial J}{\partial\theta_j}\) for MSE cost? <br/>	 \(\frac{\partial J}{\partial\theta_j} = \frac{1}{m} \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)}) \cdot x_j^{(i)}\).
nJm8^hY6tG	Basic	ML-LinearRegression	Why is MSE with linear regression guaranteed to find global minimum? <br/>	 The cost function is convex (bowl-shaped), so Gradient Descent converges to global optimum, not local minima.
bVc5%nMk9L	Basic	ML-LinearRegression	What's the difference between an epoch and an iteration? <br/>	 **Iteration:** One parameter update. **Epoch:** One full pass through entire training dataset (contains multiple iterations in mini-batch GD).
xZq1@aSw2D	Basic	ML-LinearRegression	How does Batch Gradient Descent compute gradients? <br/>	 Uses entire training set: \(\theta_j := \theta_j - \alpha\cdot\frac{1}{m} \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)}\).
cXz3#pLl8K	Basic	ML-LinearRegression	What are advantages and disadvantages of BGD? <br/>	 **Pros:** Accurate, guaranteed convergence for convex functions. **Cons:** Slow for large datasets, high memory usage, can get stuck in local minima for non-convex functions.
vBn9*mLk8J	Basic	ML-LinearRegression	How does SGD compute gradients differently from BGD? <br/>	 Uses one random example: \(\theta_j := \theta_j - \alpha\cdot (h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)}\).
hGy6^tFc5R	Basic	ML-LinearRegression	What are advantages and disadvantages of SGD? <br/>	 **Pros:** Fast, low memory, can escape local minima. **Cons:** Noisy updates, may not converge exactly, needs data shuffling.
dEf4&rTy7U	Basic	ML-LinearRegression	What is the compromise of Mini-Batch Gradient Descent? <br/>	 Uses \(b\) examples per update: \(\theta_j := \theta_j - \alpha\cdot\frac{1}{b} \sum_{i=1}^b (h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)}\). Balances speed and stability.
qWe3#yHu8I	Basic	ML-LinearRegression	What is the closed-form solution for linear regression? <br/>	 \(\theta = (X^T X)^{-1} X^T y\), where \(X\) is design matrix with rows as training examples.
aZs9*xDc2V	Basic	ML-LinearRegression	What are advantages of the Normal Equation over Gradient Descent? <br/>	 No iterations needed, no learning rate to tune, guaranteed exact solution (if \(X^TX\) invertible).
sXw1@qAz3E	Basic	ML-LinearRegression	What are limitations of the Normal Equation? <br/>	 Computationally expensive for large features (\(O(n^3)\) for inversion), fails if \(X^TX\) non-invertible (redundant features or \(n > m\)).
dCf5&vGb9N	Basic	ML-LinearRegression	When should you use Normal Equation versus Gradient Descent? <br/>	 **Normal Equation:** Small number of features (\(n < 10,000\)). **Gradient Descent:** Large \(n\), very large \(m\), or non-linear models.
fRt6%yHn8M	Basic	ML-LinearRegression	Why is MAE's gradient different from MSE? <br/>	 MAE uses \(\text{sign}(h_\theta(x^{(i)}) - y^{(i)})\) instead of \((h_\theta(x^{(i)}) - y^{(i)})\), making it non-differentiable at zero but robust to outliers.
gYh7*uJm0K	Basic	ML-LinearRegression	When might you choose MAE over MSE? <br/>	 Choose **MAE** when your data has many outliers (robust). Choose **MSE** for normally distributed errors (efficient, convex).
jKl0^iOp9L	Basic	ML-LinearRegression	What are typical mini-batch sizes and their effects? <br/>	 32, 64, 128. Larger batches: more stable but slower. Smaller batches: faster updates but noisier.
pZq2@aSw4D	Basic	ML-LinearRegression	Why might \(X^TX\) be non-invertible? <br/>	 1. Redundant/linearly dependent features. 2. More features than examples (\(n > m\)). 3. Features with zero variance.
xCd3#fVb5N	Basic	ML-LinearRegression	What's a good practice when implementing Gradient Descent? <br/>	 Plot \(J(\theta)\) versus iterations to diagnose convergence issues and choose appropriate \(\alpha\).
vFr4%gTb6M	Basic	ML-LinearRegression	What is the core paradigm of supervised learning? <br/>	 Learning a mapping from input variables \(x\) to an output variable \(y\), using a labeled dataset of example input-output pairs \(\{ (x^{(i)}, y^{(i)}) \}_{i=1}^m\).
bGt5&hYn7L	Basic	ML-LinearRegression	In linear regression, what is the form of the hypothesis function \(h_\theta(x)\) for a single feature? <br/>	 \(h_\theta(x) = \theta_0 + \theta_1 x\), where \(\theta_0\) is the intercept/bias and \(\theta_1\) is the weight/slope. It predicts the output \(\hat{y}\).
nHd6*jUm8K	Basic	ML-LinearRegression	What is the purpose of a cost function \(J(\theta)\) in machine learning? <br/>	 It quantifies the error between the model's predictions \(h_\theta(x)\) and the true targets \(y\). The learning goal is to find parameters \(\theta\) that minimize \(J(\theta)\).
mKi7(oP9lZ	Basic	ML-LinearRegression	What is the formula for the Mean Squared Error (MSE) cost function for linear regression? <br/>	 \(J(\theta) = \frac{1}{2m} \sum_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)})^2\). The \(\frac{1}{2}\) is often included to cancel the factor of 2 from differentiation.
aLp8#sDfG0	Basic	ML-LinearRegression	Describe the Gradient Descent algorithm in one sentence. <br/>	 An iterative optimization algorithm that adjusts parameters \(\theta\) by taking steps proportional to the negative gradient of the cost function \(J(\theta)\).
jKl1^iOp0L	Basic	ML-LinearRegression	Write the general parameter update rule for Gradient Descent. <br/>	 \(\theta_j := \theta_j - \alpha\frac{\partial}{\partial\theta_j} J(\theta)\), repeated simultaneously for all \(j\). \(\alpha\) is the learning rate.
sD6#gH9jKm	Basic	ML-LinearRegression	What are the consequences of setting the learning rate \(\alpha\) too small or too large? <br/>	 Too small: very slow convergence. Too large: can overshoot the minimum, causing divergence or oscillatory, slow convergence.
pLo9*iUj8H	Basic	ML-LinearRegression	What is the partial derivative \(\frac{\partial J}{\partial\theta_0}\) for the MSE cost with hypothesis \(h_\theta(x)=\theta_0+\theta_1x\)? <br/>	 \(\frac{\partial J}{\partial\theta_0} = \frac{1}{m} \sum_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)})\).
mKi0(oP1lA	Basic	ML-LinearRegression	What is the partial derivative \(\frac{\partial J}{\partial\theta_1}\) for the MSE cost with hypothesis \(h_\theta(x)=\theta_0+\theta_1x\)? <br/>	 \(\frac{\partial J}{\partial\theta_1} = \frac{1}{m} \sum_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)}) \cdot x^{(i)}\).
nJm9^hY7tH	Basic	ML-LinearRegression	Why is using (M)SE for linear regression advantageous? <br/>	 The cost function \(J(\theta)\) is convex. Gradient Descent on a convex function is guaranteed to converge to the global minimum, not a local one.
bVc6%nMk0M	Basic	ML-LinearRegression	How does Batch Gradient Descent compute the gradient in each iteration? <br/>	 It uses the **entire training set** to compute the gradient. The update for \(\theta_j\) sums over all \(m\) examples: \(\theta_j := \theta_j - \alpha\cdot\frac{1}{m} \sum_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)}) x_j^{(i)}\).
xZq2@aSw3E	Basic	ML-LinearRegression	How does Stochastic Gradient Descent compute the gradient for an update? <br/>	 It uses **one randomly chosen training example** \((x^{(i)}, y^{(i)})\) per update: \(\theta_j := \theta_j - \alpha\cdot (h_\theta(x^{(i)}) - y^{(i)}) x_j^{(i)}\).
cXz4#pLl9L	Basic	ML-LinearRegression	What is the compromise offered by Mini-batch Gradient Descent? <br/>	 It uses a small random subset (mini-batch) of size \(b\) (e.g., 32) to compute the gradient: \(\theta_j := \theta_j - \alpha\cdot\frac{1}{b} \sum_{i=1}^{b} (h_\theta(x^{(i)}) - y^{(i)}) x_j^{(i)}\).
vBn0*mLk9J	Basic	ML-LinearRegression	Distinguish between an *epoch* and an *iteration* in Gradient Descent. <br/>	 **Iteration:** One update of the model parameters. **Epoch:** One full pass through the entire training dataset (may contain many iterations, e.g., in mini-batch GD).
hGy7^tFc6S	Basic	ML-LinearRegression	What is the closed-form solution for linear regression parameters \(\theta\)? <br/>	 \(\theta = (X^T X)^{-1} X^T y\), where \(X\) is the design matrix (with a column of 1s for the intercept) and \(y\) is the target vector.
dEf5&rTy8V	Basic	ML-LinearRegression	What is the practical difference between Sum of Squared Errors (SSE) and Mean Squared Error (MSE)? <br/>	 SSE: \(J = \frac{1}{2}\sum (h-y)^2\). MSE: \(J = \frac{1}{2m}\sum (h-y)^2\). MSE normalizes by dataset size \(m\), making cost comparable across different sized datasets. Their gradients differ by a factor of \(1/m\).
qWe4#yHu9J	Basic	ML-LinearRegression	What is the Mean Absolute Error (MAE) cost function and its key property? <br/>	 \(J(\theta) = \frac{1}{m} \sum_{i=1}^m |h_\theta(x^{(i)}) - y^{(i)}|\). It is less sensitive to outliers than MSE, but its gradient involves the sign function, which is not differentiable at zero.
aZs0*xDc3W	Basic	ML-LinearRegression	What is a critical implementation rule for the vanilla Gradient Descent update step? <br/>	 All parameters \(\theta_j\) must be updated **simultaneously** using the *old* values of \(\theta\). Do not use a newly updated \(\theta_0\) to compute the update for \(\theta_1\).
sXw2@qAz4F	Basic	ML-LinearRegression	Compare the convergence behavior of BGD and SGD. <br/>	 **BGD:** Converges smoothly to the minimum. **SGD:** Converges with noise; the path is erratic. It can escape shallow local minima but may oscillate near the global minimum.
dCf6&vGb0O	Basic	ML-LinearRegression	When might you prefer Gradient Descent over the Normal Equation? <br/>	 When \(n\) (number of features) is very large (>10,000), as inverting \(X^TX\) (\(O(n^3)\)) is computationally expensive. GD scales better.
fRt7%yHn9N	Basic	ML-LinearRegression	What are two reasons the Normal Equation \(\theta = (X^TX)^{-1}X^Ty\) might fail? <br/>	 1. **Non-invertibility:** \(X^TX\) is singular if features are linearly dependent (redundant). 2. **Computational inefficiency:** If \(n\) is very large, the inversion is slow.