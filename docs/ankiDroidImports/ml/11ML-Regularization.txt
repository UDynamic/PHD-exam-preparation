#separator:tab
#html:true
#guid column:1
#notetype column:2
#deck column:3
#tags column:6
{11ML}0001	Basic	11ML-Regularization	What fundamental ML problem do we address with regularization? `<br/>`	We address the bias-variance tradeoff. Models with high variance (complex models) overfit to training data, while models with high bias (simple models) underfit. Regularization helps find the sweet spot between these extremes.<br><br>* Regularization's main purpose is to reduce variance by decreasing complexity
{11ML}0002	Basic	11ML-Regularization	In simple terms, what does regularization do to a machine learning model? `<br/>`	It "simplifies" the model by penalizing complexity, making it less likely to overfit to noise in the training data and more likely to generalize well to new, unseen data.
{11ML}0003	Basic	11ML-Regularization	What is the general mathematical form of a regularized objective function? `<br/>`	\( J(\theta) = L(\theta) + \lambda R(\theta) \)<br><br>Where \( L(\theta) \) is the original loss function, \( R(\theta) \) is the regularization term, and \( \lambda \) is the regularization parameter controlling the penalty strength.
{11ML}0004	Basic	11ML-Regularization	What happens when λ is set to 0, very small, very large, or extremely large? `<br/>`	- λ = 0: No regularization, pure loss minimization<br>- Small λ: Light regularization, slight complexity penalty (complex model that might overfit)<br>- Large λ: Strong regularization, high complexity penalty (simple model that might underfit)<br>- λ → ∞: Complete regularization, model collapses to simplest form (often all zero weights)
{11ML}0005	Basic	11ML-Regularization	What is the mathematical form and primary characteristic of L1 regularization? `<br/>`	Mathematical form:<br><br>\( R(\theta) = \sum_{i=1}^{n} |\theta_i| \)<br><br>Primary characteristic: **Sparsity** - tends to drive some parameters exactly to zero, performing automatic feature selection.
{11ML}0006	Basic	11ML-Regularization	What is the mathematical form and primary characteristic of L2 regularization? `<br/>`	Mathematical form:<br><br>\( R(\theta) = \sum_{i=1}^{n} \theta_i^2 \)<br><br>Primary characteristic: **Weight shrinkage** - shrinks all parameters toward zero but rarely makes them exactly zero, producing more stable models.<br><br>* L2 norm put's sum under the \( \sqrt{} \) but not in regularization
{11ML}0007	Basic	11ML-Regularization	How can we visualize the difference between L1 and L2 constraints? `<br/>`	L1 regularization creates a diamond-shaped feasible region (\( \sum|\theta_i| \leq t \)), where solutions often land at corners (creating sparsity). L2 creates a circular/spherical region (\( \sum\theta_i^2\leq t \)), where solutions land smoothly on the boundary (creating shrinkage).<br><br>* \( R(\theta) = \sum_{i=1}^{n} |\theta_i| < t \rightarrow\text{forms a diamond} \)<br>* \( R(\theta) = \sum_{i=1}^{n} \theta_i^2 < t \rightarrow\text{forms a circle} \)<br>* in geometric form we want to choose best combination, so we choose the point of contact on both regularization and cost function diagrams.
{11ML}0008	Basic	11ML-Regularization	What is the mathematical definition of the L0 "norm"? `<br/>`	\( \|\theta\|_0 = \sum_{j=1}^{p} \mathbb{1}(\theta_j\neq0) \)<br><br>It counts the number of non-zero parameters in the model, where \( \mathbb{1} \) is the indicator function (1 if true, 0 if false).
{11ML}0009	Basic	11ML-Regularization	What does the L0-regularized loss function look like? `<br/>`	\( J(\theta) = L(\theta) + \lambda \|\theta\|_0 \)<br><br>Where \( L(\theta) \) is the original loss (e.g., MSE), \( \lambda \) is the regularization strength, and \( \|\theta\|_0 \) counts non-zero parameters. Each additional non-zero parameter costs \( \lambda \) in the objective.
{11ML}0010	Basic	11ML-Regularization	Why is exact L0 regularization computationally challenging? `<br/>`	L0 regularization requires solving a combinatorial optimization problem. For p features, there are \( 2^p \) possible subsets to evaluate. This exponential growth makes exact solutions NP-hard for large p, requiring heuristic approximations instead.
{11ML}0011	Basic	11ML-Regularization	What geometric shape represents the L0 constraint region? `<br/>`	The L0 constraint \( \|\theta\|_0\leq k \) forms a union of coordinate subspaces. In 2D: the axes themselves. In 3D: the coordinate planes and axes. It's not a convex set like L1's diamond or L2's circle, making optimization much harder.
{11ML}0012	Basic	11ML-Regularization	How does L0 differ fundamentally from L1 regularization? `<br/>`	L0 directly counts non-zero parameters (true sparsity), while L1 sums absolute values (approximate sparsity). L1 is convex and computationally efficient; L0 is non-convex and NP-hard. L1 often approximates L0 solutions but doesn't guarantee exact zeros.
{11ML}0013	Basic	11ML-Regularization	How does L2 regularization modify the gradient descent update rule? `<br/>`	For parameter θ with learning rate α:`<br/>`<br><br>Original:<br><br>\( \theta := \theta - \alpha\frac{\partial L}{\partial\theta} \)<br><br>With L2:<br><br>\( \theta := \theta - \alpha\left(\frac{\partial L}{\partial\theta} + \lambda\theta\right) = \theta(1 - \alpha\lambda) - \alpha\frac{\partial L}{\partial\theta} \)<br><br>The additional \( -\alpha\lambda\theta \) term causes "weight decay" at each update.
{11ML}0014	Basic	11ML-Regularization	What problem does Elastic Net solve, and what is its mathematical form? `<br/>`	Elastic Net combines L1 and L2 to overcome limitations of each: L1 can be unstable with correlated features, L2 doesn't perform feature selection.<br><br>Mathematical form:<br><br>\( J(\theta) = L(\theta) + \lambda_1 R_1(\theta) + \lambda_2 R_2(\theta) \)<br><br>single regularization parameter:<br><br>\( R(\theta) = \alpha\sum|\theta_i| + (1-\alpha)\sum\theta_i^2 \)<br><br>Where α controls the mix between L1 and L2.
{11ML}0015	Basic	11ML-Regularization	In the constraint view of regularization, how does λ relate to the diamond/circle boundary? `<br/>`	λ doesn't multiply the diamond/circle coordinates. Instead, each λ value corresponds to a different **size** of the constraint region. Small λ ↔ large diamond/circle (weak constraint), large λ ↔ small diamond/circle (strong constraint). The optimal point is where a loss contour touches the constraint boundary.
{11ML}0016	Basic	11ML-Regularization	How do you find the optimal model parameters in the geometric constraint view? `<br/>`	For a given constraint size t (diamond/circle of fixed size), find where a contour of the loss function L(θ) just touches the constraint boundary. This contact point represents the optimal θ that minimizes loss while satisfying R(θ) ≤ t. Different t values give different solutions along the regularization path.
{11ML}0017	Basic	11ML-Regularization	How does early stopping work as an implicit regularization technique? `<br/>`	Training is stopped when validation error starts increasing while training error continues decreasing. This prevents the model from over-optimizing to training noise, effectively limiting model complexity by restricting training time.
{11ML}0018	Basic	11ML-Regularization	How does dropout work in neural networks, and why is it effective? `<br/>`	During training, dropout randomly "drops" (sets to zero) a percentage of neurons in each layer for each training example. This prevents co-adaptation of neurons, forcing the network to learn robust, redundant features, acting like training an ensemble of many thinned networks.
{11ML}0019	Basic	11ML-Regularization	What is weight decay and how does it relate to L2 regularization? `<br/>`	Weight decay is another name for L2 regularization. In the weight update equation, it appears as:<br><br>\( \theta := \theta - \alpha(\frac{\partial L}{\partial\theta} + \lambda\theta) = \theta(1 - \alpha\lambda) - \alpha\frac{\partial L}{\partial\theta} \)<br><br>The \( (1 - \alpha\lambda) \) factor causes exponential decay of weights toward zero at each update.
{11ML}0020	Basic	11ML-Regularization	What are three practical considerations when applying regularization? `<br/>`	1.**Cross-validation**: Use CV to find optimal λ value<br><br>2.**Feature scaling**: Regularization assumes features are on similar scales (standardize features first)<br><br>3.**Don't regularize bias**: Typically exclude the bias/intercept term from regularization penalties
{11ML}0021	Basic	11ML-Regularization	update rule for L2 in linear regression with SSE cost function? `<br/>`	\( \Delta\theta_0= -\alpha\sum_{i=1}^{m} (h_{\theta}(x^{(i)}) - y^{(i)}) \)<br><br>\( \Delta\theta_j= -\alpha [\sum_{i=1}^{m} (h_{\theta}(x^{(i)}) - y^{(i)}) \cdot x_j^{(i)} + \lambda\theta_j] \) `<br/>`<br><br>or `<br/>`<br><br>\( \theta_j = \theta_j(1 - \alpha\lambda) - \alpha(\sum_{i=1}^{m} (h_{\theta}(x^{(i)}) - y^{(i)}) \cdot x_j^{(i)}) \)
{11ML}0022	Basic	11ML-Regularization	How do L1 and L2 differ in their handling of correlated features? `<br/>`	L1 tends to select one feature from a correlated group and zero out the others. L2 tends to distribute weight among correlated features, keeping all but shrinking their coefficients. L1 performs feature selection; L2 performs feature "grouping."
{11ML}0023	Basic	11ML-Regularization	What does a regularization path plot show us? `<br/>`	It shows how model coefficients change as λ increases from 0 to large values. For L1, we see coefficients gradually shrinking to zero (creating sparsity). For L2, we see all coefficients smoothly shrinking toward zero but rarely reaching exactly zero.
{11ML}0024	Basic	11ML-Regularization	What is the Bayesian interpretation of regularization? `<br/>`	Regularization corresponds to placing a prior distribution on the parameters:<br><br>- L1 regularization ↔ Laplace (double exponential) prior<br>- L2 regularization ↔ Gaussian prior<br><br>The MAP (maximum a posteriori) estimate with these priors equals the regularized MLE estimate.
{11ML}0025	Basic	11ML-Regularization	What is the double descent phenomenon and how does it relate to regularization? `<br/>`	In modern overparameterized models, test error can decrease even as models become more complex (beyond the interpolation point). Explicit regularization or early stopping helps navigate this curve, avoiding the peak at the interpolation threshold where models fit training data perfectly but generalize poorly.