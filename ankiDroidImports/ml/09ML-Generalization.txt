#separator:tab
#html:true
#guid column:1
#notetype column:2
#deck column:3
#tags column:6

09ML0001	Basic	09ML-Generalization	What is the ideal outcome for a trained machine learning model?	Both training error and test error should be near zero:<br> \( \text{Error}_{train} \approx \text{Error}_{test} \approx 0 \).
09ML0002	Basic	09ML-Generalization	What does "bias" measure in a machine learning model? <br/>	The error from the model's inability to learn true patterns in the data. High bias means the model is oversimplified.
09ML0003	Basic	09ML-Generalization	What does "variance" measure in a machine learning model? <br/>	How much the model's predictions change when trained on different datasets. High variance means the model is too sensitive to the training data.
09ML0004	Basic	09ML-Generalization	How can you identify overfitting from error metrics? <br/>	Training error is very low but test error is high: \(Error_{train} \ll Error_{test}\).
09ML0005	Basic	09ML-Generalization	What are common causes of overfitting? <br/>	Overly complex model, too many features, too little training data, or too much noise in the data.
09ML0006	Basic	09ML-Generalization	How can you identify underfitting from error metrics? <br/>	Both training and test errors are high: \(Error_{train} \approx Error_{test} \gg 0\).
09ML0007	Basic	09ML-Generalization	What causes underfitting? <br/>	Using a model that is too simple to capture patterns in the data.
09ML0008	Basic	09ML-Generalization	How does model complexity affect bias and variance? <br/>	Low complexity → high bias, low variance. High complexity → low bias, high variance.
09ML0009	Basic	09ML-Generalization	What three components make up generalization error? <br/>	\(Generalization\ Error = (Bias)^2 + Variance + Irreducible\ Error\)
09ML0010	Basic	09ML-Generalization	Which parts of generalization error can we reduce, and which can't we? <br/>	<b>Reducible:</b> Bias and Variance (by improving the model). <b>Irreducible:</b> Noise in the data (cannot be eliminated).
09ML0011	Basic	09ML-Generalization	How can you reduce high bias in a model? <br/>	Increase model complexity, add more relevant features, or use a more powerful algorithm.
09ML0012	Basic	09ML-Generalization	How can you reduce high variance in a model? <br/>	Simplify the model, use regularization, get more training data, or reduce features.
09ML0013	Basic	09ML-Generalization	How does more training data affect bias and variance? <br/>	More data primarily reduces variance (makes model more stable) but doesn't fix high bias if the model is too simple.
09ML0014	Basic	09ML-Generalization	How does regularization help with the bias-variance tradeoff? <br/>	It penalizes overly complex models, reducing variance (preventing overfitting) while possibly slightly increasing bias.
09ML0015	Basic	09ML-Generalization	Why is cross-validation important for managing bias and variance? <br/>	It provides better estimates of test error, helping select models that generalize well (balance bias and variance).
09ML0016	Basic	09ML-Generalization	Where is the optimal model complexity located? <br/>	At the point where total generalization error is minimized, balancing bias and variance.
09ML0017	Basic	09ML-Generalization	If both training and test errors are high, what's likely the problem? <br/>	High bias (underfitting) - the model is too simple.
09ML0018	Basic	09ML-Generalization	If training error is low but test error is high, what's likely the problem? <br/>	High variance (overfitting) - the model is too complex.
09ML0019	Basic	09ML-Generalization	What causes irreducible error in machine learning? <br/>	Random noise in the data that cannot be predicted, such as measurement errors or inherent randomness.
09ML0020	Basic	09ML-Generalization	What practical steps help find the right bias-variance balance? <br/>	1. Start with simple model. 2. Gradually increase complexity while monitoring validation error. 3. Use regularization. 4. Get more data if possible.
09ML0021	Basic	09ML-Generalization	What happens to bias and variance as training data size approaches infinity? <br/>	<b>Variance approaches zero, bias remains unchanged.</b> With infinite data, the model sees all possible variations, making predictions stable (zero variance). However, bias—the model's fundamental inability to capture the true relationship—is determined by model capacity, not data quantity.
09ML0022	Basic	09ML-Generalization	What do learning curves show as training size increases toward infinity? <br/>	The gap between training and test error (variance) narrows to zero, and both converge to the same value—the bias of the model. If both errors remain high at convergence, the model has high bias (underfitting).
09ML0023	Basic	09ML-Generalization	What model should you choose if you have access to infinite data? <br/>	<b>The most complex model possible</b> (lowest bias). With infinite data, variance is zero, so the bias-variance tradeoff disappears. Complexity is free—choose the model class that can best approximate the true function.
09ML0024	Basic	09ML-Generalization	What happens to irreducible error as training data approaches infinity? <br/>	<b>Irreducible error remains constant.</b> This is the inherent noise in the data generation process (e.g., measurement error, true stochasticity). No amount of data can eliminate it, setting a lower bound on possible error.
09ML0025	Basic	09ML-Generalization	What is the ideal outcome for a well-performing machine learning model? <br/>	\(Error_{train} \approx Error_{test} \approx0\). The model performs equally well on the data it was trained on and on new, unseen data.
09ML0026	Basic	09ML-Generalization	In the context of model error, what is <i>bias</i>? <br/>	The error arising from the model's inability to represent the true underlying pattern in the data. A high-bias model is too simplistic.
09ML0027	Basic	09ML-Generalization	In the context of model error, what is <i>variance</i>? <br/>	The error arising from the model's sensitivity to fluctuations in the specific training dataset. A high-variance model is overly complex and fits the noise.
09ML0028	Basic	09ML-Generalization	What is overfitting, and what are the typical error characteristics? <br/>	The model learns the training data (including noise) too well. \(Error_{train}\) is very low, but \(Error_{test}\) is significantly higher (\(Error_{train} \ll Error_{test}\)). It corresponds to <b>high variance</b>.
09ML0029	Basic	09ML-Generalization	List three common causes of overfitting (high variance). <br/>	1. Model is too complex (e.g., high-degree polynomial). 2. Too many features relative to data points. 3. Training data contains significant noise.
09ML0030	Basic	09ML-Generalization	What is underfitting, and what are the typical error characteristics? <br/>	The model fails to learn the underlying pattern in the data. Both \(Error_{train}\) and \(Error_{test}\) are high (\(Error_{train} \approx Error_{test} \gg0\)). It corresponds to <b>high bias</b>.
09ML0031	Basic	09ML-Generalization	List two common causes of underfitting (high bias). <br/>	1. Model is too simple (e.g., linear model for a complex problem). 2. Too few features to capture the relevant patterns.
09ML0032	Basic	09ML-Generalization	How does model complexity relate to bias and variance? <br/>	<b>Low Complexity:</b> High Bias, Low Variance (underfitting). <b>High Complexity:</b> Low Bias, High Variance (overfitting). The goal is to find the optimal complexity that balances both.
09ML0033	Basic	09ML-Generalization	What is the canonical decomposition of the expected generalization error? <br/>	\(E[(y - \hat{f}(x))^2] = \text{Bias}[\hat{f}(x)]^2 + \text{Var}[\hat{f}(x)] + \sigma^2\). Where \(\sigma^2\) is the irreducible error.
09ML0034	Basic	09ML-Generalization	Distinguish between reducible and irreducible error in the bias-variance decomposition. <br/>	<b>Reducible:</b> Bias and Variance. We can reduce these by improving the model. <b>Irreducible:</b> \(\sigma^2\), the inherent noise in the data. It sets a lower bound on total error and cannot be eliminated.
09ML0035	Basic	09ML-Generalization	What actions can you take if your model is underfitting (high bias)? <br/>	Increase model complexity: Use a more powerful model (e.g., higher degree polynomial, neural network), add more relevant features, or reduce regularization strength.
09ML0036	Basic	09ML-Generalization	What actions can you take if your model is overfitting (high variance)? <br/>	Simplify the model: Use fewer features, get more training data, increase regularization strength (L1/L2), or use a simpler model class.
09ML0037	Basic	09ML-Generalization	As the training dataset size \(m \to\infty\), what happens to bias and variance? <br/>	<b>Variance \(\to0\).</b><b>Bias remains constant.</b> With infinite data, the model estimate stabilizes, but its fundamental representational capacity (bias) is unchanged.
09ML0038	Basic	09ML-Generalization	On a learning curve (error vs. training size), what do the converging training and test errors represent as \(m \to\infty\)? <br/>	They converge to the same value: the <b>bias</b> of the model plus the <b>irreducible error</b> \(\sigma^2\). The gap between them (due to variance) vanishes.
09ML0039	Basic	09ML-Generalization	If you had infinite data, what type of model would you choose and why? <br/>	The most complex, lowest-bias model possible (e.g., a very large neural network). With infinite data, variance is eliminated, so you only need to minimize bias.
09ML0040	Basic	09ML-Generalization	If both training and test error are high, is the problem always high bias? What's a key consideration? <br/>	Not always. While high bias is a likely cause, it could also be due to <b>very high variance coupled with poorly representative data</b>. Check if the training error itself is high (true bias) or if there's a massive gap to test error (variance).
09ML0041	Basic	09ML-Generalization	Why isn't "always use the most complex model" a good strategy in practice? <br/>	Because in the real world with <b>finite data</b>, increasing complexity reduces bias but increases variance. The optimal model is the one that best balances this trade-off for your specific dataset size and problem.