#separator:tab
#html:true
#guid column:1
#notetype column:2
#deck column:3
#tags column:6

u2nCw5nN9Y**	Basic	ML-LinearRegression	Linear Regression Hypothesis	"<span style=""color:gold"">Linear Regression Hypothesis<br><br>What is the hypothesis function for simple linear regression?<br><br>"	"<span style=""color:gold"">Linear Regression Hypothesis<br><br>What is the hypothesis function for simple linear regression?<br><br>\(h_{\theta}(x) = \theta_0 + \theta_1x\), where \(\theta_0\) is the intercept and \(\theta_1\) is the slope. This gives the prediction \(\hat{y}\)."	**
KHt$9q[UF!**	Basic	ML-LinearRegression	Cost Function Goal	"<span style=""color:gold"">Cost Function Goal<br><br>What is the goal when training a linear regression model?<br><br>"	"<span style=""color:gold"">Cost Function Goal<br><br>What is the goal when training a linear regression model?<br><br>To find parameters \(\theta_0, \theta_1\) that minimize the cost function \(J(\theta_0, \theta_1)\)."	**
8j1t`W!pS0**	Basic	ML-LinearRegression	SSE Cost Function	"<span style=""color:gold"">SSE Cost Function<br><br>What is the Sum of Squared Errors (SSE) cost function?<br><br>"	"<span style=""color:gold"">SSE Cost Function<br><br>What is the Sum of Squared Errors (SSE) cost function?<br><br>\(J(\theta) = \frac{1}{2} \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})^2\). The \(\frac{1}{2}\) simplifies derivatives."	**
tNz(kjY0P$**	Basic	ML-LinearRegression	MSE Cost Function	"<span style=""color:gold"">MSE Cost Function<br><br>What is Mean Squared Error (MSE) and how does it differ from SSE?<br><br>"	"<span style=""color:gold"">MSE Cost Function<br><br>What is Mean Squared Error (MSE) and how does it differ from SSE?<br><br>\(J(\theta) = \frac{1}{2m} \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})^2\). It averages error by dividing by \(m\), making it comparable across datasets."	**
yT4Qn@2*9m**	Basic	ML-LinearRegression	RMSE Cost Function	"<span style=""color:gold"">RMSE Cost Function<br><br>What is Root Mean Squared Error (RMSE)?<br><br>"	"<span style=""color:gold"">RMSE Cost Function<br><br>What is Root Mean Squared Error (RMSE)?<br><br>\(J(\theta) = \sqrt{\frac{1}{2m} \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})^2}\). It's in the same units as \(y\) for easier interpretation."	**
Yr2HpU)D3d**	Basic	ML-LinearRegression	MAE Cost Function	"<span style=""color:gold"">MAE Cost Function<br><br>What is Mean Absolute Error (MAE) and its key difference from MSE?<br><br>"	"<span style=""color:gold"">MAE Cost Function<br><br>What is Mean Absolute Error (MAE) and its key difference from MSE?<br><br>\(J(\theta) = \frac{1}{m} \sum_{i=1}^m |h_\theta(x^{(i)}) - y^{(i)}|\). Unlike MSE, it's less sensitive to outliers but uses sign() in gradient."	**
4H$pWl7Q6#**	Basic	ML-LinearRegression	Gradient Descent Algorithm	"<span style=""color:gold"">Gradient Descent Algorithm<br><br>What are the 3 main steps of Gradient Descent?<br><br>"	"<span style=""color:gold"">Gradient Descent Algorithm<br><br>What are the 3 main steps of Gradient Descent?<br><br>1. Initialize \(\theta\) randomly. 2. Update: \(\theta_j := \theta_j - \alpha\frac{\partial}{\partial\theta_j}J(\theta)\). 3. Repeat until convergence."	**
xH9sL3kM1&**	Basic	ML-LinearRegression	Learning Rate $\alpha$	"<span style=""color:gold"">Learning Rate $\alpha$<br><br>What are the effects of too small or too large learning rate $\alpha$?<br><br>"	"<span style=""color:gold"">Learning Rate $\alpha$<br><br>What are the effects of too small or too large learning rate $\alpha$?<br><br>Too small: very slow convergence. Too large: may overshoot minimum, causing divergence or oscillation."	**
pQ2rK8jT5$**	Basic	ML-LinearRegression	Convergence Condition	"<span style=""color:gold"">Convergence Condition<br><br>How do we know when Gradient Descent has converged?<br><br>"	"<span style=""color:gold"">Convergence Condition<br><br>How do we know when Gradient Descent has converged?<br><br>When parameter changes are small: \(|\Delta\theta_j| \leq \epsilon\) for all \(j\), where \(\epsilon\) is a small tolerance."	**
sL8nQ1kM2#**	Basic	ML-LinearRegression	Simultaneous Parameter Update	"<span style=""color:gold"">Simultaneous Parameter Update<br><br>Why must Gradient Descent update all parameters simultaneously?<br><br>"	"<span style=""color:gold"">Simultaneous Parameter Update<br><br>Why must Gradient Descent update all parameters simultaneously?<br><br>To ensure each gradient \(\frac{\partial J}{\partial\theta_j}\) is computed using the same parameter values before any updates."	**
aN3mK9lP4!**	Basic	ML-LinearRegression	MSE Gradient for $\theta_0$	"<span style=""color:gold"">MSE Gradient for $\theta_0$<br><br>What is \(\frac{\partial J}{\partial\theta_0}\) for MSE cost?<br><br>"	"<span style=""color:gold"">MSE Gradient for $\theta_0$<br><br>What is \(\frac{\partial J}{\partial\theta_0}\) for MSE cost?<br><br>\(\frac{\partial J}{\partial\theta_0} = \frac{1}{m} \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})\)."	**
bP4nL0mQ5&**	Basic	ML-LinearRegression	MSE Gradient for $\theta_j$	"<span style=""color:gold"">MSE Gradient for $\theta_j$<br><br>What is \(\frac{\partial J}{\partial\theta_j}\) for MSE cost?<br><br>"	"<span style=""color:gold"">MSE Gradient for $\theta_j$<br><br>What is \(\frac{\partial J}{\partial\theta_j}\) for MSE cost?<br><br>\(\frac{\partial J}{\partial\theta_j} = \frac{1}{m} \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)}) \cdot x_j^{(i)}\)."	**
cQ5oM1nR6$**	Basic	ML-LinearRegression	Convexity in Linear Regression	"<span style=""color:gold"">Convexity in Linear Regression<br><br>Why is MSE with linear regression guaranteed to find global minimum?<br><br>"	"<span style=""color:gold"">Convexity in Linear Regression<br><br>Why is MSE with linear regression guaranteed to find global minimum?<br><br>The cost function is convex (bowl-shaped), so Gradient Descent converges to global optimum, not local minima."	**
dR6pN2oS7#**	Basic	ML-LinearRegression	Epoch vs Iteration	"<span style=""color:gold"">Epoch vs Iteration<br><br>What's the difference between an epoch and an iteration?<br><br>"	"<span style=""color:gold"">Epoch vs Iteration<br><br>What's the difference between an epoch and an iteration?<br><br>**Iteration:** One parameter update. **Epoch:** One full pass through entire training dataset (contains multiple iterations in mini-batch GD)."	**
eS7qO3pT8!**	Basic	ML-LinearRegression	Batch Gradient Descent (BGD)	"<span style=""color:gold"">Batch Gradient Descent (BGD)<br><br>How does Batch Gradient Descent compute gradients?<br><br>"	"<span style=""color:gold"">Batch Gradient Descent (BGD)<br><br>How does Batch Gradient Descent compute gradients?<br><br>Uses entire training set: \(\theta_j := \theta_j - \alpha\cdot\frac{1}{m} \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)}\)."	**
fT8rP4qU9&**	Basic	ML-LinearRegression	BGD Pros and Cons	"<span style=""color:gold"">BGD Pros and Cons<br><br>What are advantages and disadvantages of BGD?<br><br>"	"<span style=""color:gold"">BGD Pros and Cons<br><br>What are advantages and disadvantages of BGD?<br><br>**Pros:** Accurate, guaranteed convergence for convex functions. **Cons:** Slow for large datasets, high memory usage, can get stuck in local minima for non-convex functions."	**
gU9sQ5rV0$**	Basic	ML-LinearRegression	Stochastic Gradient Descent (SGD)	"<span style=""color:gold"">Stochastic Gradient Descent (SGD)<br><br>How does SGD compute gradients differently from BGD?<br><br>"	"<span style=""color:gold"">Stochastic Gradient Descent (SGD)<br><br>How does SGD compute gradients differently from BGD?<br><br>Uses one random example: \(\theta_j := \theta_j - \alpha\cdot (h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)}\)."	**
hV0tR6sW1#**	Basic	ML-LinearRegression	SGD Pros and Cons	"<span style=""color:gold"">SGD Pros and Cons<br><br>What are advantages and disadvantages of SGD?<br><br>"	"<span style=""color:gold"">SGD Pros and Cons<br><br>What are advantages and disadvantages of SGD?<br><br>**Pros:** Fast, low memory, can escape local minima. **Cons:** Noisy updates, may not converge exactly, needs data shuffling."	**
iW1uS7tX2!**	Basic	ML-LinearRegression	Mini-Batch Gradient Descent	"<span style=""color:gold"">Mini-Batch Gradient Descent<br><br>What is the compromise of Mini-Batch GD?<br><br>"	"<span style=""color:gold"">Mini-Batch Gradient Descent<br><br>What is the compromise of Mini-Batch GD?<br><br>Uses \(b\) examples per update: \(\theta_j := \theta_j - \alpha\cdot\frac{1}{b} \sum_{i=1}^b (h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)}\). Balances speed and stability."	**
jX2vT8uY3&**	Basic	ML-LinearRegression	Normal Equation Method	"<span style=""color:gold"">Normal Equation Method<br><br>What is the closed-form solution for linear regression?<br><br>"	"<span style=""color:gold"">Normal Equation Method<br><br>What is the closed-form solution for linear regression?<br><br>\(\theta = (X^T X)^{-1} X^T y\), where \(X\) is design matrix with rows as training examples."	**
kY3wU9vZ4$**	Basic	ML-LinearRegression	Normal Equation Pros	"<span style=""color:gold"">Normal Equation Pros<br><br>What are advantages of the Normal Equation over Gradient Descent?<br><br>"	"<span style=""color:gold"">Normal Equation Pros<br><br>What are advantages of the Normal Equation over Gradient Descent?<br><br>No iterations needed, no learning rate to tune, guaranteed exact solution (if \(X^TX\) invertible)."	**
lZ4xV0wA5#**	Basic	ML-LinearRegression	Normal Equation Cons	"<span style=""color:gold"">Normal Equation Cons<br><br>What are limitations of the Normal Equation?<br><br>"	"<span style=""color:gold"">Normal Equation Cons<br><br>What are limitations of the Normal Equation?<br><br>Computationally expensive for large features (\(O(n^3)\) for inversion), fails if \(X^TX\) non-invertible (redundant features or \(n > m\))."	**
mA5yW1xB6!**	Basic	ML-LinearRegression	When to Use Normal Equation vs GD	"<span style=""color:gold"">When to Use Normal Equation vs GD<br><br>When should you use Normal Equation versus Gradient Descent?<br><br>"	"<span style=""color:gold"">When to Use Normal Equation vs GD<br><br>When should you use Normal Equation versus Gradient Descent?<br><br>**Normal Equation:** Small number of features (\(n < 10,000\)). **Gradient Descent:** Large \(n\), very large \(m\), or non-linear models."	**
nB6zX2yC7&**	Basic	ML-LinearRegression	MAE Gradient Computation	"<span style=""color:gold"">MAE Gradient Computation<br><br>Why is MAE's gradient different from MSE?<br><br>"	"<span style=""color:gold"">MAE Gradient Computation<br><br>Why is MAE's gradient different from MSE?<br><br>MAE uses \(\text{sign}(h_\theta(x^{(i)}) - y^{(i)})\) instead of \((h_\theta(x^{(i)}) - y^{(i)})\), making it non-differentiable at zero but robust to outliers."	**
oC7aY3zD8$**	Basic	ML-LinearRegression	Cost Function Comparison	"<span style=""color:gold"">Cost Function Comparison<br><br>When might you choose MAE over MSE?<br><br>"	"<span style=""color:gold"">Cost Function Comparison<br><br>When might you choose MAE over MSE?<br><br>Choose **MAE** when your data has many outliers (robust). Choose **MSE** for normally distributed errors (efficient, convex)."	**
pD8bZ4aE9#**	Basic	ML-LinearRegression	Batch Size in Mini-Batch GD	"<span style=""color:gold"">Batch Size in Mini-Batch GD<br><br>What are typical mini-batch sizes and their effects?<br><br>"	"<span style=""color:gold"">Batch Size in Mini-Batch GD<br><br>What are typical mini-batch sizes and their effects?<br><br>32, 64, 128. Larger batches: more stable but slower. Smaller batches: faster updates but noisier."	**
qE9cA5bF0!**	Basic	ML-LinearRegression	Non-invertible $X^TX$ Causes	"<span style=""color:gold"">Non-invertible $X^TX$ Causes<br><br>Why might $X^TX$ be non-invertible?<br><br>"	"<span style=""color:gold"">Non-invertible $X^TX$ Causes<br><br>Why might $X^TX\) be non-invertible?<br><br>1. Redundant/linearly dependent features. 2. More features than examples (\(n > m\)). 3. Features with zero variance."	**
rF0dB6cG1&**	Basic	ML-LinearRegression	Practical Gradient Descent Tip	"<span style=""color:gold"">Practical Gradient Descent Tip<br><br>What's a good practice when implementing Gradient Descent?<br><br>"	"<span style=""color:gold"">Practical Gradient Descent Tip<br><br>What's a good practice when implementing Gradient Descent?<br><br>Plot \(J(\theta)\) versus iterations to diagnose convergence issues and choose appropriate \(\alpha\)."	**
sG1eC7dH2$**	Basic	ML-LinearRegression	Supervised Learning	"<span style=""color:gold"">Supervised Learning<br><br>What is the core paradigm of supervised learning?<br><br>"	"<span style=""color:gold"">Supervised Learning<br><br>What is the core paradigm of supervised learning?<br><br>Learning a mapping from input variables \(x\) to an output variable \(y\), using a labeled dataset of example input-output pairs \(\{ (x^{(i)}, y^{(i)}) \}_{i=1}^m\)."	**
tH2fD8eI3#**	Basic	ML-LinearRegression	Hypothesis Function (Linear Model)	"<span style=""color:gold"">Hypothesis Function (Linear Model)<br><br>In linear regression, what is the form of the hypothesis function $h_\theta(x)$ for a single feature?<br><br>"	"<span style=""color:gold"">Hypothesis Function (Linear Model)<br><br>In linear regression, what is the form of the hypothesis function $h_\theta(x)$ for a single feature?<br><br>\(h_\theta(x) = \theta_0 + \theta_1 x\), where \(\theta_0\) is the intercept/bias and \(\theta_1\) is the weight/slope. It predicts the output \(\hat{y}\)."	**
uI3gE9fJ4!**	Basic	ML-LinearRegression	Cost Function - Intuition	"<span style=""color:gold"">Cost Function - Intuition<br><br>What is the purpose of a cost function $J(\theta)$ in machine learning?<br><br>"	"<span style=""color:gold"">Cost Function - Intuition<br><br>What is the purpose of a cost function $J(\theta)$ in machine learning?<br><br>It quantifies the error between the model's predictions \(h_\theta(x)\) and the true targets \(y\). The learning goal is to find parameters \(\theta\) that minimize \(J(\theta)\)."	**
vJ4hF0gK5&**	Basic	ML-LinearRegression	Mean Squared Error (MSE) Cost	"<span style=""color:gold"">Mean Squared Error (MSE) Cost<br><br>What is the formula for the Mean Squared Error (MSE) cost function for linear regression?<br><br>"	"<span style=""color:gold"">Mean Squared Error (MSE) Cost<br><br>What is the formula for the Mean Squared Error (MSE) cost function for linear regression?<br><br>\(J(\theta) = \frac{1}{2m} \sum_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)})^2\). The \(\frac{1}{2}\) is often included to cancel the factor of 2 from differentiation."	**
wK5iG1hL6$**	Basic	ML-LinearRegression	Gradient Descent - Core Idea	"<span style=""color:gold"">Gradient Descent - Core Idea<br><br>Describe the Gradient Descent algorithm in one sentence.<br><br>"	"<span style=""color:gold"">Gradient Descent - Core Idea<br><br>Describe the Gradient Descent algorithm in one sentence.<br><br>An iterative optimization algorithm that adjusts parameters \(\theta\) by taking steps proportional to the negative gradient of the cost function \(J(\theta)\)."	**
xL6jH2iM7#**	Basic	ML-LinearRegression	Gradient Descent Update Rule	"<span style=""color:gold"">Gradient Descent Update Rule<br><br>Write the general parameter update rule for Gradient Descent.<br><br>"	"<span style=""color:gold"">Gradient Descent Update Rule<br><br>Write the general parameter update rule for Gradient Descent.<br><br>\(\theta_j := \theta_j - \alpha\frac{\partial}{\partial\theta_j} J(\theta)\), repeated simultaneously for all \(j\). \(\alpha\) is the learning rate."	**
yM7kI3jN8!**	Basic	ML-LinearRegression	Learning Rate ($\alpha$)	"<span style=""color:gold"">Learning Rate ($\alpha$)<br><br>What are the consequences of setting the learning rate $\alpha$ too small or too large?<br><br>"	"<span style=""color:gold"">Learning Rate ($\alpha$)<br><br>What are the consequences of setting the learning rate $\alpha$ too small or too large?<br><br>Too small: very slow convergence. Too large: can overshoot the minimum, causing divergence or oscillatory, slow convergence."	**
zN8lJ4kO9&**	Basic	ML-LinearRegression	Partial Derivative for MSE (Intercept)	"<span style=""color:gold"">Partial Derivative for MSE (Intercept)<br><br>What is the partial derivative $\frac{\partial J}{\partial\theta_0}$ for the MSE cost with hypothesis $h_\theta(x)=\theta_0+\theta_1x$?<br><br>"	"<span style=""color:gold"">Partial Derivative for MSE (Intercept)<br><br>What is the partial derivative $\frac{\partial J}{\partial\theta_0}$ for the MSE cost with hypothesis $h_\theta(x)=\theta_0+\theta_1x$?<br><br>\(\frac{\partial J}{\partial\theta_0} = \frac{1}{m} \sum_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)})\)."	**
aO9mK5lP0$**	Basic	ML-LinearRegression	Partial Derivative for MSE (Slope)	"<span style=""color:gold"">Partial Derivative for MSE (Slope)<br><br>What is the partial derivative $\frac{\partial J}{\partial\theta_1}$ for the MSE cost with hypothesis $h_\theta(x)=\theta_0+\theta_1x$?<br><br>"	"<span style=""color:gold"">Partial Derivative for MSE (Slope)<br><br>What is the partial derivative $\frac{\partial J}{\partial\theta_1}$ for the MSE cost with hypothesis $h_\theta(x)=\theta_0+\theta_1x\)?<br><br>\(\frac{\partial J}{\partial\theta_1} = \frac{1}{m} \sum_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)}) \cdot x^{(i)}\)."	**
bP0nL6mQ1#**	Basic	ML-LinearRegression	Convexity in Linear Regression	"<span style=""color:gold"">Convexity in Linear Regression<br><br>Why is using (M)SE for linear regression advantageous?<br><br>"	"<span style=""color:gold"">Convexity in Linear Regression<br><br>Why is using (M)SE for linear regression advantageous?<br><br>The cost function \(J(\theta)\) is convex. Gradient Descent on a convex function is guaranteed to converge to the global minimum, not a local one."	**
cQ1oM7nR2!**	Basic	ML-LinearRegression	Batch Gradient Descent (BGD)	"<span style=""color:gold"">Batch Gradient Descent (BGD)<br><br>How does Batch Gradient Descent compute the gradient in each iteration?<br><br>"	"<span style=""color:gold"">Batch Gradient Descent (BGD)<br><br>How does Batch Gradient Descent compute the gradient in each iteration?<br><br>It uses the **entire training set** to compute the gradient. The update for \(\theta_j\) sums over all \(m\) examples: \(\theta_j := \theta_j - \alpha\cdot\frac{1}{m} \sum_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)}) x_j^{(i)}\)."	**
dR2pN8oS3&**	Basic	ML-LinearRegression	Stochastic Gradient Descent (SGD)	"<span style=""color:gold"">Stochastic Gradient Descent (SGD)<br><br>How does Stochastic Gradient Descent compute the gradient for an update?<br><br>"	"<span style=""color:gold"">Stochastic Gradient Descent (SGD)<br><br>How does Stochastic Gradient Descent compute the gradient for an update?<br><br>It uses **one randomly chosen training example** \((x^{(i)}, y^{(i)})\) per update: \(\theta_j := \theta_j - \alpha\cdot (h_\theta(x^{(i)}) - y^{(i)}) x_j^{(i)}\)."	**
eS3qO9pT4$**	Basic	ML-LinearRegression	Mini-batch Gradient Descent	"<span style=""color:gold"">Mini-batch Gradient Descent<br><br>What is the compromise offered by Mini-batch Gradient Descent?<br><br>"	"<span style=""color:gold"">Mini-batch Gradient Descent<br><br>What is the compromise offered by Mini-batch Gradient Descent?<br><br>It uses a small random subset (mini-batch) of size \(b\) (e.g., 32) to compute the gradient: \(\theta_j := \theta_j - \alpha\cdot\frac{1}{b} \sum_{i=1}^{b} (h_\theta(x^{(i)}) - y^{(i)}) x_j^{(i)}\)."	**
fT4rP0qU5#**	Basic	ML-LinearRegression	Epoch vs. Iteration	"<span style=""color:gold"">Epoch vs. Iteration<br><br>Distinguish between an *epoch* and an *iteration* in Gradient Descent.<br><br>"	"<span style=""color:gold"">Epoch vs. Iteration<br><br>Distinguish between an *epoch* and an *iteration* in Gradient Descent.<br><br>**Iteration:** One update of the model parameters. **Epoch:** One full pass through the entire training dataset (may contain many iterations, e.g., in mini-batch GD)."	**
gU5sQ1rV6!**	Basic	ML-LinearRegression	Normal Equation Method	"<span style=""color:gold"">Normal Equation Method<br><br>What is the closed-form solution for linear regression parameters $\theta$?<br><br>"	"<span style=""color:gold"">Normal Equation Method<br><br>What is the closed-form solution for linear regression parameters $\theta$?<br><br>\(\theta = (X^T X)^{-1} X^T y\), where \(X\) is the design matrix (with a column of 1s for the intercept) and \(y\) is the target vector."	**
hV6tR2sW7&**	Basic	ML-LinearRegression	Cost Functions: SSE vs. MSE	"<span style=""color:gold"">Cost Functions: SSE vs. MSE<br><br>What is the practical difference between Sum of Squared Errors (SSE) and Mean Squared Error (MSE)?<br><br>"	"<span style=""color:gold"">Cost Functions: SSE vs. MSE<br><br>What is the practical difference between Sum of Squared Errors (SSE) and Mean Squared Error (MSE)?<br><br>SSE: \(J = \frac{1}{2}\sum (h-y)^2\). MSE: \(J = \frac{1}{2m}\sum (h-y)^2\). MSE normalizes by dataset size \(m\), making cost comparable across different sized datasets. Their gradients differ by a factor of \(1/m\)."	**
iW7uS3tX8$**	Basic	ML-LinearRegression	Cost Functions: MAE	"<span style=""color:gold"">Cost Functions: MAE<br><br>What is the Mean Absolute Error (MAE) cost function and its key property?<br><br>"	"<span style=""color:gold"">Cost Functions: MAE<br><br>What is the Mean Absolute Error (MAE) cost function and its key property?<br><br>\(J(\theta) = \frac{1}{m} \sum_{i=1}^m |h_\theta(x^{(i)}) - y^{(i)}|\). It is less sensitive to outliers than MSE, but its gradient involves the sign function, which is not differentiable at zero."	**
jX8vT4uY9#**	Basic	ML-LinearRegression	Gradient Descent Pitfall - Simultaneous Update	"<span style=""color:gold"">Gradient Descent Pitfall - Simultaneous Update<br><br>What is a critical implementation rule for the vanilla Gradient Descent update step?<br><br>"	"<span style=""color:gold"">Gradient Descent Pitfall - Simultaneous Update<br><br>What is a critical implementation rule for the vanilla Gradient Descent update step?<br><br>All parameters \(\theta_j\) must be updated **simultaneously** using the *old* values of \(\theta\). Do not use a newly updated \(\theta_0\) to compute the update for \(\theta_1\)."	**
kY9wU5vZ0!**	Basic	ML-LinearRegression	BGD vs. SGD - Trade-offs	"<span style=""color:gold"">BGD vs. SGD - Trade-offs<br><br>Compare the convergence behavior of BGD and SGD.<br><br>"	"<span style=""color:gold"">BGD vs. SGD - Trade-offs<br><br>Compare the convergence behavior of BGD and SGD.<br><br>**BGD:** Converges smoothly to the minimum. **SGD:** Converges with noise; the path is erratic. It can escape shallow local minima but may oscillate near the global minimum."	**
lZ0xV6wA1&**	Basic	ML-LinearRegression	Normal Equation vs. GD - When to Use	"<span style=""color:gold"">Normal Equation vs. GD - When to Use<br><br>When might you prefer Gradient Descent over the Normal Equation?<br><br>"	"<span style=""color:gold"">Normal Equation vs. GD - When to Use<br><br>When might you prefer Gradient Descent over the Normal Equation?<br><br>When \(n\) (number of features) is very large (>10,000), as inverting \(X^TX\) (\(O(n^3)\)) is computationally expensive. GD scales better."	**
mA1yW7xB2$**	Basic	ML-LinearRegression	Normal Equation Limitation	"<span style=""color:gold"">Normal Equation Limitation<br><br>What are two reasons the Normal Equation $\theta = (X^TX)^{-1}X^Ty$ might fail?<br><br>"	"<span style=""color:gold"">Normal Equation Limitation<br><br>What are two reasons the Normal Equation $\theta = (X^TX)^{-1}X^Ty$ might fail?<br><br>1. **Non-invertibility:** \(X^TX\) is singular if features are linearly dependent (redundant). 2. **Computational inefficiency:** If \(n\) is very large, the inversion is slow."	**