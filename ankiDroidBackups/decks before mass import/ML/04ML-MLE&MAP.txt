#separator:tab
#html:true
#guid column:1
#notetype column:2
#deck column:3
#tags column:6
qyb9E1G13b	Basic	ML-MLE&MAP	What is Maximum Likelihood Estimation (MLE)?	MLE is a statistical method used to estimate the parameters of a model based on observed data. <br><br>Goal: Find the parameter values that maximize the probability of observing the given data.	
Qs4-zB6w_G	Basic	ML-MLE&MAP	likelihood function !? 	"<span style=""color:gold"">Conditional probability of seeing data with condition of that parameter</span><br><br>Given independent observations \(x1, x2, ..., x_n \) from a distribution with parameter \( \theta \).<br><br>the likelihood function is: <br>\(\mathcal{L}(\theta \mid x_1, x_2, \dots, x_n) = \prod_{i=1}^n P(x_i \mid \theta) \)"	
JY^(3PR7^z	Basic	ML-MLE&MAP	Log-Likelihood Function !? 	\( \ell(\theta) = \log L(\theta) = \sum_{i=1}^{n} \log P(x_i \mid \theta)\)	
JOC@m:%wNH	Basic	ML-MLE&MAP	Maximum Likelihood Estimation (MLE)	 We find the value of \( \theta \) that maximizes the log-likelihood: <br><br>\( \ell(\theta) = \log L(\theta) = \sum_{i=1}^{n} \log P(x_i \mid \theta) \)<br><br>\( \hat{\theta} = \arg\max_{\theta} \ell(\theta) \)	
P.sW0hrA75	Basic	ML-MLE&MAP	MLE for Bernoulli Distribution	"<span style=""color:gold"">All ML Estimators Except Exponential are equal to Average</span> <br>for Exponential is average reversed<br><br>\( \hat{\theta} = \frac{1}{n} \sum_{i=1}^{n} x_i \)<br><hr><br>PMF:<br>\(P(x \mid \theta) = \theta^x (1 - \theta)^{1 - x} \)<br><br>Likelihood function:<br>\( L(p \mid x_1, x_2, ..., x_n) = \prod_{i=1}^{n} P(x_i \mid p) = p^{x_i} (1 - p)^{1 - x_i} \)<br><br>Log-Likelihood: <br>\( \ell(\theta) = \sum_{i=1}^{n} \left[ x_i \log \theta + (1 - x_i) \log (1 - \theta) \right] \)"	
L?%2A3vS;z	Basic	ML-MLE&MAP	PMF for Bernoulli Distribution	"<span style=""color:gold""> Bernoulli is binary</span><br><br>One trial with two outcomes (success/failure) <br><br>\(P(x \mid p) = p^x (1 - p)^{1 - x} \)"	
EF$@Zb9)%=	Basic	ML-MLE&MAP	MLE for Normal Distribution	"<span style=""color:gold"">All ML Estimators Except Exponential are equal to Average</span> <br>for Exponential is average reversed<br><br>\(\hat{\mu} = \frac{1}{n} \sum_{i=1}^{n} x_i \)<br><br>\( \hat{\sigma}^2 = \frac{1}{n} \sum_{i=1}^{n} (x_i - \hat{\mu})^2 \)<br><hr><br>PDF for Normal Distribution <br>\( P(x \mid \mu, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(x - \mu)^2}{2\sigma^2}\right) \)<br><br><br>Likelihood:<br>\(L(\mu, \sigma^2 \mid x_1, x_2, ..., x_n) = \prod_{i=1}^{n} \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left( -\frac{(x_i - \mu)^2}{2\sigma^2} \right) = \left( \frac{1}{\sqrt{2\pi\sigma^2}} \right)^n \exp\left( -\frac{1}{2\sigma^2} \sum_{i=1}^{n} (x_i - \mu)^2 \right) \)<br><br>Log-Likelihood: <br>\(\ell(\mu, \sigma^2) = -\frac{n}{2} \log(2\pi) - \frac{n}{2} \log(\sigma^2) - \frac{1}{2\sigma^2} \sum_{i=1}^{n} (x_i - \mu)^2 \)"	
if-=p!&j{x	Basic	ML-MLE&MAP	PDF for Normal Distribution 	PDF for Normal Distribution <br>\( P(x \mid \mu, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(x - \mu)^2}{2\sigma^2}\right) \)	
tDL,fNe3Cb	Basic	ML-MLE&MAP	MLE for Poisson Distribution	"<span style=""color:gold"">All ML Estimators Except Exponential are equal to Average</span> <br>for Exponential is average reversed<br><br>PMF: <br>\(P(x \mid \lambda) = \frac{\lambda^xe^{-\lambda} }{x!} \)<br><br>Likelihood:<br>\( L(\lambda \mid x_1, x_2, \dots, x_n) = \prod_{i=1}^{n} \frac{\lambda^{x_i} e^{-\lambda}}{x_i!} \)<br><br>Log-Likelihood: <br>\(\ell(\lambda) = \sum_{i=1}^{n} \left[ x_i \ln \lambda - \lambda - \ln(x_i!) \right]\)<br>\(\frac{d\ell(\lambda)}{d\lambda} = \sum_{i=1}^{n} \left( \frac{x_i}{\lambda} - 1 \right)\)<br><br>\(\sum_{i=1}^{n} \left( \frac{x_i}{\lambda} - 1 \right) = 0\)<br><br>\(\sum_{i=1}^{n} \frac{x_i}{\lambda} = n\)<br><br>\( \hat{\lambda} = \frac{1}{n} \sum_{i=1}^{n} x_i \)<br>"	
miDVI<S:lF	Basic	ML-MLE&MAP	PMF for Poisson distribution 	"<span style=""color:gold"">Like Exponential with X to the power and X factorial to the bottom </span><br><br>Number of events in a time interval<br><br>PMF: <br>\(P(x \mid \lambda) = \frac{\lambda^xe^{-\lambda} }{x!} \)"	
K~=.gyJ,|!	Basic	ML-MLE&MAP	MLE for Exponential Distribution	"<span style=""color:gold"">Only Distribution with ML estimator reverse of the average</span><br>allothers are equal to the average<br><br>\(\hat{\lambda} = \frac{1}{\bar{x}} = \frac{n}{\sum x_i} \)<br><hr><br> PDF:<br> \( P(x \mid \lambda) = \lambda e^{-\lambda x} \) for \(x \geq 0 \)<br><br><br>Likelihood:<br>\( L(\lambda \mid x_1, x_2, \dots, x_n) = \prod_{i=1}^{n} \lambda e^{-\lambda x_i} = \lambda^n e^{-\lambda \sum_{i=1}^{n} x_i} \)<br><br><br>Log-Likelihood: <br>\(\ell(\lambda) = n \log \lambda - \lambda \sum_{i=1}^{n} x_i \)<br>"	
gw.ao-4QO+	Basic	ML-MLE&MAP	PDF for Exponential distribution	 PDF:<br> \( P(x \mid \lambda) = \lambda e^{-\lambda x} \) for \(x \geq 0 \)	
N;Y~{7ob=[	Basic	ML-MLE&MAP	<h3>PMF for Binomial Distribution</h3>	The Binomial distribution models the number of successes in a fixed number of independent trials, where each trial has the same probability of success<br><br>\(P(X = k) = \binom{n}{k} p^k (1 - p)^{n - k}\)	
A*l)`xW!yA	Basic	ML-MLE&MAP	<h3>Likelihood Function for theBinomial distribution</h3>	"\(L(p; k, n) = \binom{n}{k} p^k (1 - p)^{n - k} \)<br><br><span style=""color:pink"">This is the same as the PMF, but now we treat \(p\) as the unknown variable and \(k\) ,  \(n\) as known</span>"	
"vS&#|)hAvV"	Basic	ML-MLE&MAP	Log-Likelihood Function for Binomial distribution	\(\ell(p; k, n) = \log L(p; k, n)  \)<br>=<br>\( \log \binom{n}{k} + k \log p + (n - k) \log (1 - p)\)	
y@:t6gVPJ+	Basic	ML-MLE&MAP	MLE for Binomial distribution	"PMF: <br>\(P(X = k) = \binom{n}{k} p^k (1 - p)^{n - k}\)<br><br>\(L(p) = \prod_{i=1}^{n} \binom{n}{x_i} p^{x_i} (1 - p)^{n - x_i}\)<br><br>\(\ell(p) = \sum_{i=1}^{n} \left[ \ln\binom{n}{x_i} + x_i \ln p + (n - x_i) \ln(1 - p) \right]\) <br><br>\(\frac{d\ell(p)}{dp} = \sum_{i=1}^{n} \left[ \frac{x_i}{p} - \frac{n - x_i}{1 - p} \right] = 0\) <br><br>\(\sum_{i=1}^{n} \left[ x_i (1 - p) - (n - x_i) p \right] = 0\)<br> <br><span style=""color:maroon"">\(\sum_{i=1}^{n} \left[ x_i - n p \right] = 0\)</span><br><br>\(\hat{p} = \frac{k}{n}\) "	
rLqOnT<])B	Basic	ML-MLE&MAP	PMF for Geometric Distribution	Number of trials until the first success.<br>last trial as success<br><br>\(P(X=k) = (1-p)^{k-1} p\)	
Ri`6_@7`j(	Basic	ML-MLE&MAP	PMF for Negative Binomial	Number of trials until  \(r\)  successes<br><br>\(P(X=k) = \binom{k-1}{r-1} p^r (1-p)^{k-r}\)	
J<@/{{dyXH	Basic	ML-MLE&MAP	PDF for Uniform distribution	Equal probability for all values<br><br>Discrete:<br>\(p(x) = \frac{1}{b-a+1}\)<br><br>Continuous:<br>\(p(x) = \frac{1}{b-a}\)	
w~<y4>kQ*^	Basic	ML-MLE&MAP	PMF for Hypergeometric distribution 	Sampling without replacement<br><br>\(P(X=k) = \frac{\binom{K}{k} \binom{N-K}{n-k}}{\binom{N}{n}}\)<br><br>\(N\): Total number of items in the population.<br>\(K\): Number of success states in the population. (wanted outcome population)<br>\(n\): Number of draws (sample size).<br>\(k\): Number of wanted observed successes.	
jA1Le9J%9:	Basic	ML-MLE&MAP	PDF for Gama distribution 	Modeling waiting times for random events (e.g., machine repair time) Time between events in a Poisson process Bayesian statistics and modeling positive data<br><br>\(f(x; k, \theta) = \frac{x^{k-1} e^{-x/\theta}}{\theta^k \Gamma(k)} \quad \text{for } x > 0\) <br><br>Where \(\Gamma(k)\)  is the Gamma function: <br>\(\Gamma(k) = \int_0^\infty x^{k-1} e^{-x} dx\)<br><br> \(k > 0\) : Shape  <br>\(\theta > 0\) : Scale<br>Or sometimes expressed as: <br>\(\alpha\) = k : Shape<br>\(\beta = 1/\theta\) : Rate<br><br>Mean (Expected Value) :<br> \(\mu = k\theta\)<br><br>Variance \(\sigma^2 = k\theta^2\) <br><br>Mode (Most Likely Value) \((k - 1)\theta\)  (for \(k \geq 1\) )	
LVF4$-5ySv	Basic	ML-MLE&MAP	for \(f(x) = c\), <br><br>\(f'\)	"\(f'(x) = 0 \)<br><br><br><span style=""color:pink"">\(f(x) = c \cdot g(x) \to f'(x) = c \cdot g'(x)\)</span>"	
e4+Z5N6%/v	Basic	ML-MLE&MAP	for \(f(x) = x^n\)<br><br>\(f'\)	\(f'(x) = n x^{n-1}\)	
"qv#-;<7bn("	Basic	ML-MLE&MAP	for \(f(x) = g(x) \pm h(x)\) <br><br>\(f'\)	\(f'(x) = g'(x) \pm h'(x)\)	
u~K$_IJqb3	Basic	ML-MLE&MAP	for \(f(x) = g(x) \cdot h(x)\)<br><br>\(f'\)	\(f'(x) = g'(x) \cdot h(x) + g(x) \cdot h'(x)\)	
Lola.R!?)7	Basic	ML-MLE&MAP	for \(f(x) = \frac{g(x)}{h(x)}\)<br><br>\(f'\)	\(f'(x) = \frac{g'(x) \cdot h(x) - g(x) \cdot h'(x)}{[h(x)]^2}\)	
DA`HqR|P*>	Basic	ML-MLE&MAP	for \(f(x)=\frac{1}{g(x)}\)<br><br>\(f'\)	\(f'(x)= - \frac{-g'(x)}{g^2(x)}\)	
j!$*l7nc~?	Basic	ML-MLE&MAP	Chain Rule for \(f(x) = g(h(x))\)<br><br>\(f'\)	\(f'(x) = h'(x) \cdot g'(h(x))\)	
vY,xVVR=iF	Basic	ML-MLE&MAP	Trigonometric Derivatives<br><br>simple	"<span style=""color:gold"">\(d\) clockwise, \(\int\) counter clockwise</span><br><br>\(\frac{d}{dx} \sin(x) = \cos(x)\)<br>\(\frac{d}{dx} \cos(x) = -\sin(x)\)"	
A+yI)LT<>0	Basic	ML-MLE&MAP	Trigonometric Derivatives<br><br>Arc versions	\(\frac{d}{dx} \sin^{-1}(x) = \frac{1}{\sqrt{1-x^2}}\)<br><br>\(\frac{d}{dx} \cos^{-1}(x) = -\frac{1}{\sqrt{1-x^2}}\)<br><br>\(\frac{d}{dx} \tan^{-1}(x) = \frac{1}{\sqrt{1+x^2}}\)	
c[YyY*Mz<b	Basic	ML-MLE&MAP	Trigonometric Derivatives<br><br>sec & csc	\(\sec(x) = \frac{1}{\cos(x)}\)<br>\(\csc(x) = \frac{1}{\sin(x)}\)<br><br>\(\frac{d}{dx} \sec(x) = \sec(x)\tan(x)\)<br>\(\frac{d}{dx} \csc(x) = -\csc(x)\cot(x)\)	
GDE-eJ-<5F	Basic	ML-MLE&MAP	Trigonometric Derivatives<br><br>tan & cot	<br>\(\sec(x) = \frac{1}{\cos(x)}\)<br>\(\csc(x) = \frac{1}{\sin(x)}\)<br><br>\(\frac{d}{dx} \tan(x) = \sec^2(x)\)<br>\(\frac{d}{dx} \cot(x) = -\csc^2(x)\)	
bkNvjuI(7b	Basic	ML-MLE&MAP	for \(f(x) = ax^n\)<br><br>\(f'\)	"\(f'(x) = a (n) x^{n-1}\)<br><br><span style=""color:pink"">\(f(x) = a \sqrt{x} = a x^{-\frac{1}{2}}\) <br>\(\to \)<br>\(f'(x) = -a \cdot \frac{1}{2} \cdot \frac{1}{x^{-\frac{1}{2}}} =  \frac{-a}{2\sqrt{x}}\)</span>"	
OGb=,Y(7*[	Basic	ML-MLE&MAP	for \(f(x) = e^x\)<br><br>\(f'\)	\(f'(x) = e^x\)	
gSSf^8?eYT	Basic	ML-MLE&MAP	for \(f(x) = a^x\)<br><br>\(f'\)	\(f'(x) = \ln(x) a^x\)	
f?~{A5W*DZ	Basic	ML-MLE&MAP	for \(f(x) = \log_a(x)\)<br><br>\(f'\)	"\(f'(x) = \frac{1}{\ln(a)x}\)<br><br><span style=""color:pink"">\(f(x) = \ln(x) \to f'(x) = \frac{1}{x}\) </span>"	
TDpe!V&+I	Basic	ML-MLE&MAP	MLE for Uniform distribution	"(PDF): <br>\(f(x; a, b) = \begin{cases} \frac{1}{b - a}, & \text{if } a \leq x \leq b \\ 0, & \text{otherwise} \end{cases}\)<br><br>\(L(a, b) = \prod_{i=1}^{n} f(x_i; a, b) \)<br>\(L(a, b) =\left( \frac{1}{b - a} \right)^n \quad \text{if } a \leq x_i \leq b \text{ for all } i \)<br><br>\(\hat{a} = \min(x1, x2, \dots, x_n)\)\)<br>\(\hat{b} = \max(x1, x2, \dots, x_n)\)\) <br><br><span style=""color:pink"">One parameter uniform Distribution</span><br>\(f(x; \theta) = \begin{cases} \frac{1}{\theta}, & \text{if } 0 \leq x \leq \theta \\ 0, & \text{otherwise} \end{cases}\)<br><br>\(L(\theta) = \prod_{i=1}^{n} f(x_i; \theta) = \prod_{i=1}^{n} \frac{1}{\theta} = \left( \frac{1}{\theta} \right)^n\)<br><br>\(\hat{\theta} = \max(X_1, X_2, \dots, X_n)\)"	
