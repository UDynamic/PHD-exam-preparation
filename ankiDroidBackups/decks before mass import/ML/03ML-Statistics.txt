#separator:tab
#html:true
#guid column:1
#notetype column:2
#deck column:3
#tags column:6
s{N:t7Nq@C	Basic	ML-Statistics	For A as an Event<br><br>\(A' = not A\)<br><br>\(P(A')\)	\(P(A') = 1 - P(A)\)	
o&Fn.<0R];	Basic	ML-Statistics	\(P(A \cup B))\)	\(P(A \cup B) = P(A) + P(B) - P(A \cap B)\)	
gh*)ZO.$t%	Basic	ML-Statistics	\(P(A \cap B)\)	"\(P(A \cap B) = P(A) + P(B) - P(A \cup B)\)<br><br><span style=""color:pink"">\(P(A \cap B) = P(B|A) \cdot P(A)\)</span><br><br><span style=""color:pink"">\(P(A \cap B) = P(A|B) \cdot P(B)\)</span>"	
"tp|c#m/nM6"	Basic	ML-Statistics	<h3>Bayes' Theorem</h3><br><br>\(P(A|B) \)	"\(P(A|B) = \frac{P(A \cap B)}{P(B)}, \quad \text{for } P(B) > 0\)<br><hr><br>Bayes' Theorem<br><span style=""color:pink"">\(P(A \cap B) = P(B|A) \cdot P(A)\)</span><br><br><span style=""color:pink"">\(P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}\)</span>"	
LvH!I:7O.l	Basic	ML-Statistics	Bayes' Theorem<br>	\(P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}\)	
L7h6yY9MAJ	Basic	ML-Statistics	Bayes' Theorem Namings	"Bayes' Theorem<br>\(P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}\)<br><hr><br>\(P(A|B) : \textbf{Posterior}\) <br><span style=""color:gold"">Is</span><br>\(P(B|A) : \textbf{Likelihood}\)<br><span style=""color:gold"">Times</span> <br>\(P(A) : \textbf{Prior}\)<br><span style=""color:gold"">On</span><br>\(P(B) : \textbf{Evidence}\)"	
erH:B_mXp0	Basic	ML-Statistics	<h2>Mathematical Expectation</h2><br><h3>Discrete</h3>	"\(\mathbb{E}[X] = \sum_{x} p(x) \cdot f(x)\)<br><br>\(p(x)\): PDF for \(f(x)\)<br>\(f(x)\): output Event for \(x\)<br><br><span style=""color:pink"">For \(f(x)=x\)<br>\(\mathbb{E}[X] = \sum_{x} x \cdot P(x)\)</span>"	
so|E2%0^GG	Basic	ML-Statistics	<h2>Mathematical Expectation</h2><br><h3>Continuous</h3>	"\(\mathbb{E}[X] = \int_{-\infty}^{\infty} p(x) \cdot f(x) \, dx \)<br><br>\(p(x)\): PMF for \(f(x)\)<br>\(f(x)\): output Event for \(x\)<br><br><span style=""color:pink"">For \(f(x)=x\)<br>\(\mathbb{E}[X] = \int_{-\infty}^{\infty} x \cdot p(x) \, dx \)</span>"	
pZ8/O^^><c	Basic	ML-Statistics	<h2>Mathematical Expectation</h2><br><h3>Conditional</h3>	"<span style=""color:gold"">Not like Bayes</span><br><br>\(\mathbb{E}_x [f|y] = \sum_{x} p(x|y) \cdot f(x)\)<br><br>\(\mathbb{E}_x [f|y] = \int_{-\infty}^{\infty} p(x|y) \cdot f(x) \, dx\)"	
~&GuLKqb!	Basic	ML-Statistics	<h2>PDF for Uniform Distribution</h2> <br><h3>Discrete</h3>	"for \(a < x < b\)<br><br>\(P(x) = \frac{1}{b-a+1}, \quad x = 1, 2, ..., n\)<br><br><span style=""color:cyan"">\(P(x) = \frac{1}{n}, \quad x = 1, 2, ..., n\)</span>"	
"J#1+_*Mtl5"	Basic	ML-Statistics	<h2>PMF for Uniform Distribution</h2> <br><h3>Continuous</h3>	\(\text{for } a \leq x \leq b\)<br><br>\(P(x) = \frac{1}{b - a}\)	
NKphn,&&NO	Basic	ML-Statistics	<h2>Mathematical Expectation</h2><br><h3>Uniform Distribution - Discrete</h3>	"\(\mathbb{E}[X] = \frac{1}{n} \cdot \sum_{x}f(x)\)<br><br>\(p(x)\): PDF for \(f(x)\)<br>\(f(x)\): output Event for \(x\)<br><br><span style=""color:pink"">For \(f(x)=x\)<br>\(\mathbb{E}[X] = \frac{1}{n} \cdot \sum_{x} x\)</span>"	
"s#rxyYaWC2"	Basic	ML-Statistics	<h2>for \mathbb{E}[X] as Mathematical Expectation of X</h2><br><h3>\(\mathbb{E}[X+Y]\)</h3>	\(\mathbb{E}[X+Y] = \mathbb{E}[X] + \mathbb{E}[Y]\)	
kB02KDhS:F	Basic	ML-Statistics	<h3>Mathematical Expectation for </h3><br>\(\mathbb{E}[XY]\)	"Discrete<br>\(\mathbb{E}[XY] = \sum_{x} \sum_{y} x y \cdot P(x,y) \quad \)<br><br>Continuous<br>\(\mathbb{E}[XY] = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} x y \cdot P(x, y) \, dx \, dy \quad\)<br><br>\(P(x,y)\): Joint probability<br><br><span style=""color:pink"">If X and Y are independent<br>\(p(X, Y) = p(X) \cdot p(Y)\)</span><br>\(\mathbb{E}[XY] = \mathbb{E}[X] \cdot \mathbb{E}[Y]\)<br><br>"	
t{Qa<_qCnb	Basic	ML-Statistics	<h2>for \mathbb{E}[X] as Mathematical Expectation of X and C as a Constant</h2><br><h3>\(\mathbb{E}[c + f(x)]\)</h3>	\(\mathbb{E}[c + f(x)] = c + \mathbb{E}[f(x)]\)	
i(ty9==|Ci	Basic	ML-Statistics	<h2>for \(\mathbb{E}[X]\) as Mathematical Expectation of X also c and b as Constants</h2><br><h3>\(\mathbb{E}[cX + b]\)</h3>	<h3>\(\mathbb{E}[cX + b] = c \mathbb{E}[X] + b\)</h3>	
iiDlMVxyNp	Basic	ML-Statistics	<h2>for \(\mathbb{E}[X]\) as Mathematical Expectation of X also c as a Constant</h2><br><h3>\(\mathbb{E}[c]\)</h3>	\(\mathbb{E}[c] = c\)	
EuJV8(B5uH	Basic	ML-Statistics	\(Var(x)\)	"\(Var(x) = \mathbb{E}[(X-\mu)^2]\)<br>\(= \mathbb{E}[X^2] - \mathbb{E}[X]^2\)<br><br>Matrix form:<br><span style=""color:pink"">\(Var(x) = \mathbb{E}[(X - \mathbb{E}[X])(X - \mathbb{E}[X])^T]\)</span>"	
"yTFe,=#nRl"	Basic	ML-Statistics	<h3>Conditional Mean (Expected Value) of Bivariate Normal Distribution</h3>	"If  \(\mathbf{X} = [x_1, x_2]^T\)  follows a bivariate normal distribution, then:<br>\(\mathbf{X} \sim \mathcal{N}\left( \mu, \Sigma \right)\),<br>\(\mu = [\mu_1, \mu_2]\),<br>\(\Sigma = \begin{bmatrix} \sigma_1^2 & \sigma \\ \sigma & \sigma_2^2 \end{bmatrix}\),<br><br>Then The conditional distribution  \(p(x_1 \mid x_2 = a)\)  is also normal. <br><br>\(\mathbb{E}[x_1 \mid x_2 = a] = \mu_1 + \frac{\sigma}{\sigma_2^2}(a - \mu_2)\) <br><br><span style=""color:cyan"">\(\mathbb{E}[x_2 \mid x_1 = a] = \mu_2 + \frac{\sigma}{\sigma_1^2}(a - \mu_1)\)</span>"	
tGr-c]i_s[	Basic	ML-Statistics	<h3>Conditional Variance of Bivariate Normal Distribution</h3>	"If  \(\mathbf{X} = [x_1, x_2]^T\)  follows a bivariate normal distribution, then:<br>\(\mathbf{X} \sim \mathcal{N}\left( \mu, \Sigma \right)\),<br>\(\mu = [\mu_1, \mu_2]\),<br>\(\Sigma = \begin{bmatrix} \sigma_1^2 & \sigma \\ \sigma & \sigma_2^2 \end{bmatrix}\),<br><br>Then The conditional distribution  \(p(x_1 \mid x_2 = a)\)  is also normal. <br><br>\(\text{Var}(x_1 \mid x_2 = a) = \sigma_1^2 - \frac{\sigma^2}{\sigma_2^2}\)<br><br><span style=""color:cyan"">\(\text{Var}(x_2 \mid x_1 = a) = \sigma_2^2 - \frac{\sigma^2}{\sigma_1^2}\)</span>"	
BIMS;5`wX8	Basic	ML-Statistics	<h3>Marginal probability of \(X\) in a Joint probability of \(P(X, Y)\)</h3>	"Discrete:<br>\(P(X = x) = \sum_{y} P(X = x, Y = y)\)<br><span style=""color:cyan"">\(P(Y = y) = \sum_{x} P(X = x, Y = y)\)</span><br><br>Continuous:<br>\(f_X(x) = \int_{-\infty}^{\infty} f_{X,Y}(x, y) \, dy\)<br><span style=""color:cyan"">\(f_Y(y) = \int_{-\infty}^{\infty} f_{X,Y}(x, y) \, dx\)</span>"	
iV_yL0Ky9^	Basic	ML-Statistics	<h3>Boundaries of Joint Probability</h3>	\(0 \leq P(X=x, Y=y) \leq 1\)	
h{,FsE}i.g	Basic	ML-Statistics	<h3>Sum of all the Joint Probabilities</h3>	\(\sum_x \sum_y P(X=x, Y=y) = 1\)	
ej=[N>WHVx	Basic	ML-Statistics	<h3>Conditional Probability From the joint probabilities</h3>	"\(P(X = x \mid Y = y) = \frac{P(X = x, Y = y)}{P(Y = y)}\)<br><br><span style=""color:cyan"">\(P(Y = y \mid X = x) = \frac{P(X = x, Y = y)}{P(X = x)}\)</span>"	
NCC5@?`0Me	Basic	ML-Statistics	<h3>Expected ValueFrom the joint distribution</h3>	"Discrete:<br>\(\mathbb{E}[X] = \sum_{x} \sum_{y} x \cdot P(X = x, Y = y)\)<br><span style=""color:cyan"">\(\mathbb{E}[Y] = \sum_{x} \sum_{y} y \cdot P(X = x, Y = y)\)</span><br><br>Continuous:<br>\(\mathbb{E}[X] = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} x \cdot f_{X,Y}(x, y) \, dx \, dy\)<br><span style=""color:cyan"">\(\mathbb{E}[Y] = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} y \cdot f_{X,Y}(x, y) \, dx \, dy\)</span><br><br><span style=""color:pink"">Apparently orders of summation and diffrentiation doesn't matter unless specific boundaries for y or x. Even in that case the answer will be the same</span>"	
"JOBAV<RRV#"	Basic	ML-Statistics	<h3>Covariance between  \(X\)  and  \(Y\)  in Joint probability</h3>	\(\text{Cov}(X, Y) = \mathbb{E}[XY] - \mathbb{E}[X]\mathbb{E}[Y]\)	
"svNoKRwTn#"	Basic	ML-Statistics	<h3>Variance in Joint probability</h3>	"\(\text{Var}(X) = \mathbb{E}[X^2] - (\mathbb{E}[X])^2\)<br><br>Calculations:<br><span style=""color:pink"">\(\mathbb{E}[X] = \sum_{x} \sum_{y} x \cdot P(X = x, Y = y)\)<br>\(\mathbb{E}[X^2] = \sum_{x} \sum_{y} x^2 \cdot P(X = x, Y = y)\)</span>"	
"Gm%M%R#L|="	Basic	ML-Statistics	<h3>Covariance of X and Y</h3>	\(\text{Cov}(X,Y) = \mathbb{E}[(X - \mathbb{E}[X])(Y - \mathbb{E}[Y])]\)	
wPAs/_$g_v	Basic	ML-Statistics	<h3>High Positive \(\text{Cov}(X,Y)\)</h3>	strong positive linear relationship.  	
Hv>=$TiGL8	Basic	ML-Statistics	<h3>\(\text{Cov}(X,Y) â‰ˆ 0\)</h3>	no linear relationship. 	
HQlnnvk$L]	Basic	ML-Statistics	<h3>High Negative \(\text{Cov}(X,Y)\):</h3>	  strong negative linear relationship.	
i,L`7*(N^Z	Basic	ML-Statistics	<h3>Valid Covariance Matrix</h3>	"For \(A_{n*n}\):<br><br>1. Symmetric <br>(\(\sigma_{12}^2 = \sigma_{21}^2\))<br><br>2. Main Diameter None zero<br>(\(Var = \sigma^2\))<br><br>3. Positive Semi_Definite<br>(\(X^T\Sigma X \geq 0\))<br><br>4. \(\det(A) \neq Negative\)<br><span style=""color:pink"">Could be Zero and Irreversible</span><br><br>5. Cauchy-Schwarz inequality:<br>\(|Cov(i, j)| \leq \sigma_i \sigma_j \)<br><br>\(-1 \leq Corr(i, j) = \frac{Cov(i, j)}{\sigma_i \sigma_j} \leq 1\)<br>\(\sigma_i = \sqrt{Var}\)"	
j`J$:i6~~)	Basic	ML-Statistics	<h3>Correlation</h3>	"\(-1 \leq Corr(i, j) = \frac{Cov(i, j)}{\sigma_i \sigma_j} \leq 1\)<br><br><span style=""color:cyan"">Correlation is Covariance Normalized </span><br><br><span style=""color:pink"">\(Cov(i, j) = \sigma_{ij}\)</span><br><span style=""color:pink"">\(stdv : \sigma_i = \sqrt{\sigma_i^2}\)</span><br><span style=""color:pink"">\(Var =\sigma_i^2\)</span>"	
F)&wv+9D~	Basic	ML-Statistics	<h3>\(\text{Var}(\mathbf{x} + \mathbf{b})\)</h3>	"\(\text{Var}(\mathbf{x} + \mathbf{b}) = \text{Var}(\mathbf{x}) = \Sigma\)<br><br><span style=""color:pink"">\(\text{Cov}(\mathbf{x} + \mathbf{b}) = \text{Cov}(\mathbf{x}) = \Sigma\)</span>"	
KFXZ>Xmw8=	Basic	ML-Statistics	\(\text{Var}(\mathbf{A}\mathbf{x})\)	"For Covariance matrix<br>\(\text{Var}(\mathbf{x}) = \Sigma\)<br><br>\(\text{Var}(\mathbf{A}\mathbf{x}) = \mathbf{A} \Sigma \mathbf{A}^\top\)<br><br><span style=""color:pink"">\(\text{Cov}(\mathbf{A}\mathbf{x}) = \mathbf{A} \Sigma \mathbf{A}^\top\)</span><br><br><span style=""color:pink"">\(\text{Cov}(\mathbf{A}\mathbf{x}, \mathbf{A}\mathbf{x}) = \mathbf{A} \Sigma \mathbf{A}^\top\)</span>"	
e}Oczyj;jl	Basic	ML-Statistics	<h3>\(\text{Cov}(\mathbf{x} + \mathbf{a}, \mathbf{y} + \mathbf{b})\)</h3>	\( \text{Cov}(\mathbf{x} + \mathbf{a}, \mathbf{y} + \mathbf{b}) = \text{Cov}(\mathbf{x}, \mathbf{y})\)	
z&I*A>jzYC	Basic	ML-Statistics	<h3>\(\text{Cov}(\mathbf{A}\mathbf{x}, \mathbf{B}\mathbf{y}) \)</h3>	\(\text{Cov}(\mathbf{A}\mathbf{x}, \mathbf{B}\mathbf{y}) = \mathbf{A} \cdot \text{Cov}(\mathbf{x}, \mathbf{y}) \cdot \mathbf{B}^\top\)	
si?x5um!^D	Basic	ML-Statistics	<h3>\(\text{Var}(cX)\)</h3>	"Random variable X and Constant c<br><br>\(\text{Var}(cX) = c^2 \cdot \text{Var}(X)\)<br><br>\(\text{Cov}(cX) = c^2 \cdot \text{Cov}(X)\)<br><br><span style=""color:pink"">For The covariance Matrix is the same too</span>"	
t)K`gu3=CE	Basic	ML-Statistics	<h3>\(\text{Var}(aX + bY)\)</h3>	\(\text{Var}(aX + bY) = a^2 \text{Var}(X) + b^2 \text{Var}(Y) + 2ab \cdot \text{Cov}(X, Y)\)	
xX|!@&2xZV	Basic	ML-Statistics	<h3>\(\text{Cov}(aX, bY)\)</h3>	\(\text{Cov}(aX, bY) = ab \cdot \text{Cov}(X, Y)\)	
